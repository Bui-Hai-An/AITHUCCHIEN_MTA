{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b000455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Generating text using model: gemini-2.5-flash ...\n",
      "‚úÖ Text generation complete!\n",
      "\n",
      "üìú K·∫øt qu·∫£ sinh vƒÉn b·∫£n:\n",
      "\n",
      "Tuy·ªát v·ªùi! V·ªõi vai tr√≤ l√† m·ªôt nh√† thi·∫øt k·∫ø n·ªôi dung, t√¥i hi·ªÉu r·∫±ng m·ªôt t·ªù g·∫•p kh√¥ng ch·ªâ l√† th√¥ng tin m√† c√≤n l√† m·ªôt tr·∫£i nghi·ªám c·∫£m x√∫c, m·ªôt l·ªùi k√™u g·ªçi h√†nh ƒë·ªông. Ch√∫ng ta s·∫Ω t·∫°o ra m·ªôt t·ªù g·∫•p A4 g·∫•p ba, m·ªói m·∫£nh 10x21cm, v·ªõi n·ªôi dung g·∫ßn g≈©i, c·∫£m x√∫c v√† truy·ªÅn c·∫£m h·ª©ng, ph√π h·ª£p ƒë·ªÉ ph√°t t·∫°i c√°c ƒëi·ªÉm c√¥ng c·ªông, b·ªánh vi·ªán, ƒëi·ªÉm du l·ªãch v√† kh√°ch s·∫°n.\n",
      "\n",
      "**Ch·ªß ƒê·ªÅ: \"H√ÉY CH·ªåN T∆Ø∆†NG LAI, KH√îNG PH·∫¢I CH·∫§T K√çCH TH√çCH\"**\n",
      "*Chi·∫øn d·ªãch truy·ªÅn th√¥ng c·ªông ƒë·ªìng ph√≤ng, ch·ªëng ch·∫•t k√≠ch th√≠ch nƒÉm 2025*\n",
      "\n",
      "---\n",
      "\n",
      "### **C·∫•u tr√∫c t·ªù g·∫•p A4 g·∫•p ba (6 m·∫∑t)**\n",
      "\n",
      "*(H√£y h√¨nh dung t·ªù A4 ƒë∆∞·ª£c g·∫•p l√†m 3. Khi c·∫ßm tr√™n tay, b·∫°n s·∫Ω th·∫•y M·∫∑t 1 (Trang b√¨a), M·∫∑t 5 (G√°y trong) v√† M·∫∑t 6 (Trang b√¨a sau). Khi m·ªü ra, b·∫°n s·∫Ω th·∫•y M·∫∑t 2, M·∫∑t 3, M·∫∑t 4 n·∫±m li·ªÅn k·ªÅ nhau.)*\n",
      "\n",
      "---\n",
      "\n",
      "**M·∫∂T 1: TRANG B√åA (10x21cm)**\n",
      "\n",
      "*   **H√¨nh ·∫£nh:** M·ªôt b√†n tay tr·∫ª em nh·ªè x√≠u n·∫Øm l·∫•y m·ªôt b√†n tay ng∆∞·ªùi l·ªõn ·∫•m √°p, ph√≠a sau l√† khung c·∫£nh ho√†ng h√¥n t∆∞∆°i ƒë·∫πp ho·∫∑c b√¨nh minh r·∫°ng r·ª°, t∆∞·ª£ng tr∆∞ng cho hy v·ªçng v√† t∆∞∆°ng lai. (Ho·∫∑c h√¨nh ·∫£nh m·ªôt con ƒë∆∞·ªùng r·ªông m·ªü, ph√≠a xa l√† √°nh s√°ng r·ª±c r·ª°).\n",
      "*   **Ti√™u ƒë·ªÅ L·ªõn (Font m·∫°nh m·∫Ω, d·ªÖ ƒë·ªçc):**\n",
      "    **H√ÉY CH·ªåN T∆Ø∆†NG LAI, KH√îNG PH·∫¢I CH·∫§T K√çCH TH√çCH**\n",
      "*   **D√≤ng ph·ª• (Font nh·∫π nh√†ng, truy·ªÅn c·∫£m):**\n",
      "    \"M·ªôt quy·∫øt ƒë·ªãnh h√¥m nay, ƒë·ªãnh ƒëo·∫°t c·∫£ cu·ªôc ƒë·ªùi mai sau.\"\n",
      "*   **Logo:** (V·ªã tr√≠ nh·ªè g·ªçn ·ªü g√≥c d∆∞·ªõi) Logo Chi·∫øn d·ªãch Ph√≤ng Ch·ªëng Ch·∫•t K√≠ch Th√≠ch 2025.\n",
      "\n",
      "---\n",
      "\n",
      "**M·∫∂T 5: G√ÅY TRONG (10x21cm)**\n",
      "*(Khi m·ªü b√¨a ra, ƒë√¢y l√† ph·∫ßn ƒë·∫ßu ti√™n b·∫°n th·∫•y b√™n trong, th∆∞·ªùng l√† l·ªùi d·∫´n nh·∫≠p)*\n",
      "\n",
      "*   **Ti√™u ƒë·ªÅ:** **KHO·∫¢NH KH·∫ÆC H∆ØNG PH·∫§N HAY V·ª∞C S√ÇU H·ªêI H·∫¨N?**\n",
      "*   **N·ªôi dung:**\n",
      "    \"Trong cu·ªôc s·ªëng, ƒë√¥i khi ch√∫ng ta ƒë·ª©ng tr∆∞·ªõc nh·ªØng l·ª±a ch·ªçn. C√≥ nh·ªØng l·ª±a ch·ªçn mang l·∫°i ni·ªÅm vui t·ª©c th·ªùi, nh∆∞ng l·∫°i ƒë√°nh ƒë·ªïi b·∫±ng c·∫£ m·ªôt t∆∞∆°ng lai. Ch·∫•t k√≠ch th√≠ch (nh∆∞ ma t√∫y, r∆∞·ª£u bia qu√° m·ª©c, thu·ªëc l√° ƒëi·ªán t·ª≠, v.v.) c√≥ th·ªÉ ban ƒë·∫ßu mang l·∫°i c·∫£m gi√°c 'th·ªèa m√£n', 'gi·∫£i t·ªèa', nh∆∞ng ƒë√≥ ch·ªâ l√† ·∫£o ·∫£nh. ƒê·∫±ng sau l·ªõp m√†n m·ªù ·∫£o ·∫•y l√† nh·ªØng h·ªá l·ª•y kh√¥n l∆∞·ªùng, s·∫µn s√†ng nu·ªët ch·ª≠ng ∆∞·ªõc m∆°, s·ª©c kh·ªèe v√† h·∫°nh ph√∫c c·ªßa b·∫°n.\"\n",
      "*   **H√¨nh ·∫£nh nh·ªè:** M·ªôt h√¨nh ·∫£nh tr·ª´u t∆∞·ª£ng th·ªÉ hi·ªán s·ª± \"m√™ ho·∫∑c\" c·ªßa ch·∫•t k√≠ch th√≠ch (v√≠ d·ª•: v√≤ng xo√°y m√†u t·ªëi, √°nh ƒë√®n m·ªù ·∫£o,...)\n",
      "\n",
      "---\n",
      "\n",
      "**M·∫∂T 6: TRANG B√åA SAU (10x21cm)**\n",
      "\n",
      "*   **Ti√™u ƒë·ªÅ:** **C·ªòNG ƒê·ªíNG CHUNG TAY, V√å M·ªòT T∆Ø∆†NG LAI TRONG L√ÄNH**\n",
      "*   **N·ªôi dung:**\n",
      "    \"Cu·ªôc chi·∫øn ch·ªëng l·∫°i ch·∫•t k√≠ch th√≠ch kh√¥ng ph·∫£i c·ªßa ri√™ng ai. N√≥ c·∫ßn s·ª± chung tay c·ªßa c·∫£ c·ªông ƒë·ªìng.\n",
      "    *   **ƒê·ªëi v·ªõi b·∫£n th√¢n:** H√£y n√≥i KH√îNG d·ª©t kho√°t.\n",
      "    *   **ƒê·ªëi v·ªõi gia ƒë√¨nh:** H√£y l√† ƒëi·ªÉm t·ª±a, l√† n∆°i chia s·∫ª, l√† t·∫•m g∆∞∆°ng s√°ng.\n",
      "    *   **ƒê·ªëi v·ªõi x√£ h·ªôi:** H√£y l√™n ti·∫øng, t·ªë gi√°c, b·∫£o v·ªá nh·ªØng ng∆∞·ªùi y·∫øu th·∫ø.\n",
      "    *   **H√£y lan t·ªèa th√¥ng ƒëi·ªáp n√†y:** ƒê·ªÉ m·ªói ng∆∞·ªùi, m·ªói gia ƒë√¨nh ƒë·ªÅu ƒë∆∞·ª£c s·ªëng trong b√¨nh y√™n v√† h·∫°nh ph√∫c.\"\n",
      "*   **Th√¥ng tin li√™n h·ªá/H·ªó tr·ª£:**\n",
      "    *   **ƒê∆∞·ªùng d√¢y n√≥ng h·ªó tr·ª£:** 1900 xxxx (T·ªïng ƒë√†i t∆∞ v·∫•n s·ª©c kh·ªèe/ph√≤ng ch·ªëng t·ªá n·∫°n x√£ h·ªôi)\n",
      "    *   **Website:** www.chontuonglai.vn (ho·∫∑c t√™n website chi·∫øn d·ªãch)\n",
      "    *   **M√£ QR:** (ƒê·ªÉ d·∫´n ƒë·∫øn website ho·∫∑c trang th√¥ng tin chi ti·∫øt)\n",
      "*   **Logo:** Logo c√°c ƒë∆°n v·ªã ƒë·ªìng h√†nh/t√†i tr·ª£ (n·∫øu c√≥).\n",
      "*   **L·ªùi k√™u g·ªçi cu·ªëi:** \"C·∫£m ∆°n b·∫°n ƒë√£ ƒë·ªçc v√† c√πng ch√∫ng t√¥i h√†nh ƒë·ªông!\"\n",
      "\n",
      "---\n",
      "\n",
      "**M·∫∂T 2: B√äN TRONG (10x21cm)**\n",
      "*(Khi m·ªü t·ªù g·∫•p ra ho√†n to√†n, ƒë√¢y l√† m·∫∑t b√™n tr√°i nh·∫•t)*\n",
      "\n",
      "*   **Ti√™u ƒë·ªÅ:** **C√ÅI GI√Å ƒê·∫ÆT ƒê·ªé C·ª¶A M·ªòT GI√ÇY PH√öT L·∫¶M L·ª†**\n",
      "*   **N·ªôi dung:**\n",
      "    \"S·ª≠ d·ª•ng ch·∫•t k√≠ch th√≠ch l√† c√°nh c·ª≠a d·∫´n ƒë·∫øn nh·ªØng bi k·ªãch kh√¥ng ai mong mu·ªën, h·ªßy ho·∫°i t·ª´ng ph·∫ßn cu·ªôc s·ªëng c·ªßa b·∫°n:\n",
      "    *   **S·ª©c kh·ªèe tan t√†nh:** Gan, th·∫≠n, tim, ph·ªïi... t·∫•t c·∫£ ƒë·ªÅu b·ªã t√†n ph√°. H·ªá mi·ªÖn d·ªãch suy y·∫øu, nguy c∆° m·∫Øc c√°c b·ªánh truy·ªÅn nhi·ªÖm (HIV/AIDS, vi√™m gan B, C) tƒÉng cao.\n",
      "    *   **T√¢m tr√≠ u t·ªëi:** G√¢y r·ªëi lo·∫°n t√¢m th·∫ßn, tr·∫ßm c·∫£m, lo √¢u, ·∫£o gi√°c, m·∫•t ki·ªÉm so√°t h√†nh vi. B·∫°n kh√¥ng c√≤n l√† ch√≠nh m√¨nh, m√† b·ªã ƒëi·ªÅu khi·ªÉn b·ªüi ch·∫•t g√¢y nghi·ªán.\n",
      "    *   **T√†i ch√≠nh ki·ªát qu·ªá:** Ti·ªÅn b·∫°c ƒë·ªôi n√≥n ra ƒëi nhanh ch√≥ng ƒë·ªÉ th·ªèa m√£n c∆°n nghi·ªán, d·∫´n ƒë·∫øn n·ª£ n·∫ßn, tr·ªôm c·∫Øp, b√°n r·∫ª danh d·ª±.\n",
      "    *   **M·∫•t ƒëi ch√≠nh m√¨nh:** T·ª´ m·ªôt ng∆∞·ªùi c√≥ ∆∞·ªõc m∆°, ho√†i b√£o, b·∫°n tr·ªü th√†nh n√¥ l·ªá c·ªßa ch·∫•t k√≠ch th√≠ch, ƒë√°nh m·∫•t gi√° tr·ªã b·∫£n th√¢n, s·ª± t·ª± tr·ªçng v√† ni·ªÅm tin c·ªßa m·ªçi ng∆∞·ªùi.\"\n",
      "*   **H√¨nh ·∫£nh:** M·ªôt h√¨nh ·∫£nh ·∫©n d·ª• v·ªÅ s·ª± suy s·ª•p (v√≠ d·ª•: m·ªôt chi·∫øc ƒë·ªìng h·ªì v·ª°, m·ªôt c√¢y kh√¥ h√©o, m·ªôt g∆∞∆°ng m·∫∑t bu·ªìn b√£, √°nh m·∫Øt v√¥ h·ªìn).\n",
      "\n",
      "---\n",
      "\n",
      "**M·∫∂T 3: B√äN TRONG (10x21cm)**\n",
      "*(M·∫∑t gi·ªØa khi m·ªü t·ªù g·∫•p ra ho√†n to√†n)*\n",
      "\n",
      "*   **Ti√™u ƒë·ªÅ:** **N·ªñI ƒêAU KH√îNG C·ª¶A RI√äNG AI**\n",
      "*   **N·ªôi dung:**\n",
      "    \"T√°c h·∫°i c·ªßa ch·∫•t k√≠ch th√≠ch kh√¥ng ch·ªâ d·ª´ng l·∫°i ·ªü c√° nh√¢n ng∆∞·ªùi s·ª≠ d·ª•ng, m√† c√≤n lan r·ªông nh∆∞ m·ªôt v·∫øt d·∫ßu loang, t√†n ph√° nh·ªØng g√¨ thi√™ng li√™ng nh·∫•t:\n",
      "    *   **Gia ƒë√¨nh tan v·ª°:** H·∫°nh ph√∫c, b√¨nh y√™n c·ªßa t·ªï ·∫•m b·ªã ph√° h·ªßy. Con c√°i b∆° v∆°, cha m·∫π ƒëau kh·ªï, v·ª£ ch·ªìng ly t√°n. M·ªëi quan h·ªá r·∫°n n·ª©t, ni·ªÅm tin s·ª•p ƒë·ªï.\n",
      "    *   **M·∫ßm m·ªëng t·ªôi √°c:** ƒê·ªÉ c√≥ ti·ªÅn s·ª≠ d·ª•ng ch·∫•t k√≠ch th√≠ch, nhi·ªÅu ng∆∞·ªùi s·∫µn s√†ng ph·∫°m t·ªôi (tr·ªôm c·∫Øp, c∆∞·ªõ gi·∫≠t, l·ª´a ƒë·∫£o...). G√¢y m·∫•t an ninh tr·∫≠t t·ª± x√£ h·ªôi.\n",
      "    *   **G√°nh n·∫∑ng x√£ h·ªôi:** Chi ph√≠ ƒëi·ªÅu tr·ªã, cai nghi·ªán t·ªën k√©m. Ngu·ªìn l·ª±c x√£ h·ªôi b·ªã l√£ng ph√≠. H√¨nh ·∫£nh ƒë·∫•t n∆∞·ªõc, con ng∆∞·ªùi b·ªã ·∫£nh h∆∞·ªüng.\n",
      "    *   **M·∫•t ƒëi t∆∞∆°ng lai th·∫ø h·ªá:** Khi nh·ªØng ng∆∞·ªùi tr·∫ª sa ng√£, t∆∞∆°ng lai c·ªßa c·∫£ m·ªôt th·∫ø h·ªá b·ªã ƒëe d·ªça. S·ª©c lao ƒë·ªông gi·∫£m s√∫t, tr√≠ tu·ªá kh√¥ng ƒë∆∞·ª£c ph√°t huy.\"\n",
      "*   **H√¨nh ·∫£nh:** M·ªôt h√¨nh ·∫£nh c·∫£m ƒë·ªông v·ªÅ gia ƒë√¨nh (v√≠ d·ª•: m·ªôt b√†n tay cha m·∫π c·ªë n√≠u gi·ªØ tay con, nh∆∞ng tay con l·∫°i h∆∞·ªõng v·ªÅ m·ªôt th·ª© kh√°c; ho·∫∑c h√¨nh ·∫£nh gia ƒë√¨nh sum v·∫ßy nh∆∞ng c√≥ m·ªôt kho·∫£ng tr·ªëng).\n",
      "\n",
      "---\n",
      "\n",
      "**M·∫∂T 4: B√äN TRONG (10x21cm)**\n",
      "*(M·∫∑t b√™n ph·∫£i nh·∫•t khi m·ªü t·ªù g·∫•p ra ho√†n to√†n)*\n",
      "\n",
      "*   **Ti√™u ƒë·ªÅ:** **T∆Ø∆†NG LAI N·∫∞M TRONG TAY B·∫†N!**\n",
      "*   **N·ªôi dung:**\n",
      "    \"D√π b·∫°n ƒëang ·ªü ƒë√¢u tr√™n h√†nh tr√¨nh cu·ªôc ƒë·ªùi, d√π b·∫°n ƒë√£ t·ª´ng l·∫ßm l·ª° hay ch∆∞a, h√£y nh·ªõ r·∫±ng:\n",
      "    *   **B·∫°n C√ì QUY·ªÄN L·ª∞A CH·ªåN:** L·ª±a ch·ªçn s·ªëng kh·ªèe m·∫°nh, s·ªëng c√≥ √≠ch, s·ªëng tr·ªçn v·∫πn v·ªõi nh·ªØng ng∆∞·ªùi m√¨nh y√™u th∆∞∆°ng.\n",
      "    *   **B·∫°n C√ì S·ª®C M·∫†NH:** S·ª©c m·∫°nh ƒë·ªÉ n√≥i KH√îNG, s·ª©c m·∫°nh ƒë·ªÉ v∆∞·ª£t qua c√°m d·ªó, s·ª©c m·∫°nh ƒë·ªÉ l√†m l·∫°i t·ª´ ƒë·∫ßu.\n",
      "    *   **ƒê·ª´ng ng·∫ßn ng·∫°i t√¨m ki·∫øm s·ª± gi√∫p ƒë·ª°:** H√£y chia s·∫ª v·ªõi gia ƒë√¨nh, b·∫°n b√®, th·∫ßy c√¥, ho·∫∑c c√°c t·ªï ch·ª©c h·ªó tr·ª£. B·∫°n kh√¥ng h·ªÅ ƒë∆°n ƒë·ªôc!\n",
      "    *   **M·ªói ng√†y l√† m·ªôt c∆° h·ªôi:** ƒê·ªÉ thay ƒë·ªïi, ƒë·ªÉ h√†n g·∫Øn, ƒë·ªÉ x√¢y d·ª±ng l·∫°i nh·ªØng g√¨ ƒë√£ m·∫•t. H√£y ƒë·∫∑t m·ª•c ti√™u, ki√™n tr√¨ theo ƒëu·ªïi v√† tin v√†o b·∫£n th√¢n.\n",
      "    *   **H√£y l√† ng∆∞·ªùi h√πng c·ªßa ch√≠nh m√¨nh:** Tr·ªü th√†nh phi√™n b·∫£n t·ªët ƒë·∫πp nh·∫•t c·ªßa b·∫£n th√¢n, l√† ni·ªÅm t·ª± h√†o c·ªßa gia ƒë√¨nh v√† ƒë√≥ng g√≥p v√†o m·ªôt c·ªông ƒë·ªìng vƒÉn minh, kh·ªèe m·∫°nh.\"\n",
      "*   **H√¨nh ·∫£nh:** M·ªôt h√¨nh ·∫£nh ƒë·∫ßy hy v·ªçng, t∆∞∆°i s√°ng (v√≠ d·ª•: m·ªôt ng∆∞·ªùi tr·∫ª ƒëang v∆∞∆°n tay ƒë√≥n √°nh n·∫Øng m·∫∑t tr·ªùi, m·ªôt con ƒë∆∞·ªùng xanh m√°t d·∫´n ƒë·∫øn ch√¢n tr·ªùi, m·ªôt gia ƒë√¨nh ƒëang n·∫Øm tay nhau m·ªâm c∆∞·ªùi).\n",
      "*   **L·ªùi k√™u g·ªçi h√†nh ƒë·ªông:**\n",
      "    **H√ÉY H√ÄNH ƒê·ªòNG NGAY H√îM NAY, V√å M·ªòT NG√ÄY MAI T∆Ø∆†I S√ÅNG!**\n",
      "\n",
      "---\n",
      "\n",
      "### **Ghi ch√∫ Thi·∫øt K·∫ø Chung:**\n",
      "\n",
      "*   **\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ThucChienTextGenerator:\n",
    "   \"\"\"Client sinh vƒÉn b·∫£n qua gateway AI Th·ª±c Chi·∫øn (chu·∫©n OpenAI + Gemini compatible).\"\"\"\n",
    "\n",
    "\n",
    "   def __init__(self,\n",
    "                base_url: str = \"https://api.thucchien.ai\",\n",
    "                api_key: Optional[str] = None,\n",
    "                debug: bool = False):\n",
    "       self.base_url = base_url.rstrip(\"/\")\n",
    "       self.api_key = api_key or os.getenv(\"LITELLM_API_KEY\", \"\")\n",
    "       self.debug = debug\n",
    "       self.headers = {\n",
    "           \"Content-Type\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "       }\n",
    "\n",
    "\n",
    "   def generate_text(self,\n",
    "                     prompt: str,\n",
    "                     model: str = \"gemini-2.5-flash\",\n",
    "                     system_prompt: str = \"You are a helpful AI assistant.\",\n",
    "                     temperature: float = 0.7,\n",
    "                     max_tokens: int = 4096) -> Optional[str]:\n",
    "       \"\"\"\n",
    "       Sinh vƒÉn b·∫£n b·∫±ng m√¥ h√¨nh AI Th·ª±c Chi·∫øn (t·ª± ƒë·ªông nh·∫≠n d·∫°ng c·∫•u tr√∫c JSON ph·∫£n h·ªìi).\n",
    "\n",
    "\n",
    "       Args:\n",
    "           prompt: n·ªôi dung y√™u c·∫ßu sinh vƒÉn b·∫£n\n",
    "           model: model c·∫ßn d√πng (vd: gemini-2.5-flash, gemini-2.0-pro, mistral, claude)\n",
    "           system_prompt: h∆∞·ªõng d·∫´n cho model\n",
    "           temperature: ƒë·ªô s√°ng t·∫°o (0‚Äì1)\n",
    "           max_tokens: s·ªë token t·ªëi ƒëa\n",
    "       \"\"\"\n",
    "       url = f\"{self.base_url}/chat/completions\"\n",
    "\n",
    "\n",
    "       payload = {\n",
    "           \"model\": model,\n",
    "           \"temperature\": temperature,\n",
    "           \"max_tokens\": max_tokens,\n",
    "           \"messages\": [\n",
    "               {\"role\": \"system\", \"content\": system_prompt},\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ]\n",
    "       }\n",
    "\n",
    "\n",
    "       print(f\"üß† Generating text using model: {model} ...\")\n",
    "\n",
    "\n",
    "       try:\n",
    "           response = requests.post(url, headers=self.headers, data=json.dumps(payload))\n",
    "           response.raise_for_status()\n",
    "           data = response.json()\n",
    "\n",
    "\n",
    "           if self.debug:\n",
    "               print(\"\\n--- RAW RESPONSE ---\")\n",
    "               print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "               print(\"--------------------\\n\")\n",
    "\n",
    "\n",
    "           text_output = None\n",
    "\n",
    "\n",
    "           # ‚úÖ 1. Chu·∫©n OpenAI\n",
    "           if \"choices\" in data:\n",
    "               choice = data[\"choices\"][0]\n",
    "               if \"message\" in choice and \"content\" in choice[\"message\"]:\n",
    "                   text_output = choice[\"message\"][\"content\"]\n",
    "               elif \"delta\" in choice and \"content\" in choice[\"delta\"]:\n",
    "                   text_output = choice[\"delta\"][\"content\"]\n",
    "\n",
    "\n",
    "           # ‚úÖ 2. Chu·∫©n Gemini API\n",
    "           elif \"candidates\" in data:\n",
    "               candidate = data[\"candidates\"][0]\n",
    "               if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n",
    "                   text_output = candidate[\"content\"][\"parts\"][0].get(\"text\", \"\")\n",
    "               elif \"output_text\" in candidate:\n",
    "                   text_output = candidate[\"output_text\"]\n",
    "\n",
    "\n",
    "           # ‚úÖ 3. Chu·∫©n LiteLLM proxy\n",
    "           elif \"output_text\" in data:\n",
    "               text_output = data[\"output_text\"]\n",
    "\n",
    "\n",
    "           # ‚úÖ Kh√¥ng c√≥ n·ªôi dung h·ª£p l·ªá\n",
    "           if not text_output:\n",
    "               print(\"‚ö†Ô∏è Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung t·ª´ ph·∫£n h·ªìi:\")\n",
    "               print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "               return None\n",
    "\n",
    "\n",
    "           print(\"‚úÖ Text generation complete!\\n\")\n",
    "           return text_output.strip()\n",
    "\n",
    "\n",
    "       except requests.RequestException as e:\n",
    "           print(f\"‚ùå Request failed: {e}\")\n",
    "           if e.response is not None:\n",
    "               try:\n",
    "                   print(json.dumps(e.response.json(), indent=2))\n",
    "               except:\n",
    "                   print(e.response.text)\n",
    "           return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================== MAIN ======================\n",
    "def main():\n",
    "   base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai\")\n",
    "   api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-JJytUYWGmr5BGv9rVurb2Q\")\n",
    "\n",
    "\n",
    "   generator = ThucChienTextGenerator(base_url=base_url, api_key=api_key, debug=False)\n",
    "\n",
    "\n",
    "   prompt = \"\"\" B·∫°n l√† m·ªôt nh√† thi·∫øt k·∫ø t√†i ba, h√£y t·∫°o cho t√¥i n·ªôi dung c·ªßa t·ªù flyer k√≠ch c·ª° A4 g·∫•p ba (10x21cm m·ªôt m·∫£nh) ch·ªß ƒë·ªÅ tuy√™n truy·ªÅn n√¢ng cao nh·∫≠n th·ª©c v·ªÅ t√°c h·∫°i, h·∫≠u qu·∫£ c·ªßa ch·∫•t k√≠ch th√≠ch (nh∆∞ ma tu√Ω, r∆∞·ª£u bia...) cho c·ªông ƒë·ªìng t·∫°i c√°c ƒëi·ªÉm du l·ªãch, b·ªánh vi·ªán, n∆°i c√¥ng c·ªông.T·ªù g·∫•p n√†y s·∫Ω ƒë∆∞·ª£c ph√°t t·∫°i c√°c ƒëi·ªÉm c√¥ng c·ªông, b·ªánh vi·ªán l·ªõn, ƒëi·ªÉm du l·ªãch, kh√°ch s·∫°n trong chi·∫øn d·ªãch truy·ªÅn th√¥ng c·ªông ƒë·ªìng ph√≤ng, ch·ªëng ch·∫•t k√≠ch th√≠ch nƒÉm 2025. N·ªôi dung c·∫ßn ch√∫ tr·ªçng l√† Vi·ªác s·ª≠ d·ª•ng c√°c ch·∫•t k√≠ch th√≠ch (ma tu√Ω, r∆∞·ª£u bia, ‚Ä¶) d·∫´n t·ªõi nhi·ªÅu h·ªá qu·∫£ ti√™u c·ª±c ƒë·ªëi v·ªõi c√° nh√¢n v√† c·ªông ƒë·ªìng, c·∫ßn s√°ng t·∫°o n·ªôi dung g·∫ßn g≈©i, c·∫£m x√∫c, truy·ªÅn c·∫£m h·ª©ng ƒë·ªÉ gi√°o d·ª•c, c·∫£nh b√°o, ph√≤ng ng·ª´a.\"\"\"\n",
    "\n",
    "\n",
    "   result = generator.generate_text(\n",
    "       prompt=prompt,\n",
    "       model=\"gemini-2.5-flash\",\n",
    "       system_prompt=\"B·∫°n l√† m·ªôt nh√† thi·∫øt k·∫ø n·ªôi dung t√†i ba\"\n",
    "   )\n",
    "\n",
    "\n",
    "   if result:\n",
    "       print(\"üìú K·∫øt qu·∫£ sinh vƒÉn b·∫£n:\\n\")\n",
    "       print(result)\n",
    "   else:\n",
    "       print(\"‚ùå Kh√¥ng sinh ƒë∆∞·ª£c vƒÉn b·∫£n.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9477b",
   "metadata": {},
   "source": [
    "D√π b·∫°n ƒëang ·ªü ƒë√¢u tr√™n h√†nh tr√¨nh cu·ªôc ƒë·ªùi, d√π b·∫°n ƒë√£ t·ª´ng l·∫ßm l·ª° hay ch∆∞a, h√£y nh·ªõ r·∫±ng:\n",
    "    *   B·∫°n C√ì QUY·ªÄN L·ª∞A CH·ªåN: L·ª±a ch·ªçn s·ªëng kh·ªèe m·∫°nh, s·ªëng c√≥ √≠ch, s·ªëng tr·ªçn v·∫πn v·ªõi nh·ªØng ng∆∞·ªùi m√¨nh y√™u th∆∞∆°ng.\n",
    "    *   B·∫°n C√ì S·ª®C M·∫†NH: S·ª©c m·∫°nh ƒë·ªÉ n√≥i KH√îNG, s·ª©c m·∫°nh ƒë·ªÉ v∆∞·ª£t qua c√°m d·ªó, s·ª©c m·∫°nh ƒë·ªÉ l√†m l·∫°i t·ª´ ƒë·∫ßu.\n",
    "    *   ƒê·ª´ng ng·∫ßn ng·∫°i t√¨m ki·∫øm s·ª± gi√∫p ƒë·ª°: H√£y chia s·∫ª v·ªõi gia ƒë√¨nh, b·∫°n b√®, th·∫ßy c√¥, ho·∫∑c c√°c t·ªï ch·ª©c h·ªó tr·ª£. B·∫°n kh√¥ng h·ªÅ ƒë∆°n ƒë·ªôc!\n",
    "    *   M·ªói ng√†y l√† m·ªôt c∆° h·ªôi: ƒê·ªÉ thay ƒë·ªïi, ƒë·ªÉ h√†n g·∫Øn, ƒë·ªÉ x√¢y d·ª±ng l·∫°i nh·ªØng g√¨ ƒë√£ m·∫•t. H√£y ƒë·∫∑t m·ª•c ti√™u, ki√™n tr√¨ theo ƒëu·ªïi v√† tin v√†o b·∫£n th√¢n.\n",
    "    *   H√£y l√† ng∆∞·ªùi h√πng c·ªßa ch√≠nh m√¨nh: Tr·ªü th√†nh phi√™n b·∫£n t·ªët ƒë·∫πp nh·∫•t c·ªßa b·∫£n th√¢n, l√† ni·ªÅm t·ª± h√†o c·ªßa gia ƒë√¨nh v√† ƒë√≥ng g√≥p v√†o m·ªôt c·ªông ƒë·ªìng vƒÉn minh, kh·ªèe m·∫°nh.\"\n",
    "*\n",
    "*   **L·ªùi k√™u g·ªçi h√†nh ƒë·ªông:**\n",
    "    **H√ÉY H√ÄNH ƒê·ªòNG NGAY H√îM NAY, V√å M·ªòT NG√ÄY MAI T∆Ø∆†I S√ÅNG!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda4caf",
   "metadata": {},
   "source": [
    "\n",
    "Cu·ªôc chi·∫øn ch·ªëng l·∫°i ch·∫•t k√≠ch th√≠ch kh√¥ng ph·∫£i c·ªßa ri√™ng ai. N√≥ c·∫ßn s·ª± chung tay c·ªßa c·∫£ c·ªông ƒë·ªìng.\n",
    "    *   **ƒê·ªëi v·ªõi b·∫£n th√¢n:** H√£y n√≥i KH√îNG d·ª©t kho√°t.\n",
    "    *   **ƒê·ªëi v·ªõi gia ƒë√¨nh:** H√£y l√† ƒëi·ªÉm t·ª±a, l√† n∆°i chia s·∫ª, l√† t·∫•m g∆∞∆°ng s√°ng.\n",
    "    *   **ƒê·ªëi v·ªõi x√£ h·ªôi:** H√£y l√™n ti·∫øng, t·ªë gi√°c, b·∫£o v·ªá nh·ªØng ng∆∞·ªùi y·∫øu th·∫ø.\n",
    "    *   **H√£y lan t·ªèa th√¥ng ƒëi·ªáp n√†y:** ƒê·ªÉ m·ªói ng∆∞·ªùi, m·ªói gia ƒë√¨nh ƒë·ªÅu ƒë∆∞·ª£c s·ªëng trong b√¨nh y√™n v√† h·∫°nh ph√∫c.\"\n",
    "*   **Th√¥ng tin li√™n h·ªá/H·ªó tr·ª£:**\n",
    "    *   **ƒê∆∞·ªùng d√¢y n√≥ng h·ªó tr·ª£:** 1900 1502 (T·ªïng ƒë√†i t∆∞ v·∫•n s·ª©c kh·ªèe/ph√≤ng ch·ªëng t·ªá n·∫°n x√£ h·ªôi)\n",
    "    *   **Website:** www.chontuonglai.vn (ho·∫∑c t√™n website chi·∫øn d·ªãch)\n",
    "    *   **M√£ QR:** (ƒê·ªÉ d·∫´n ƒë·∫øn website ho·∫∑c trang th√¥ng tin chi ti·∫øt)\n",
    "*   **Logo:** Logo c√°c ƒë∆°n v·ªã ƒë·ªìng h√†nh/t√†i tr·ª£ (n·∫øu c√≥).\n",
    "*   **L·ªùi k√™u g·ªçi cu·ªëi:** \"C·∫£m ∆°n b·∫°n ƒë√£ ƒë·ªçc v√† c√πng ch√∫ng t√¥i h√†nh ƒë·ªông!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dddff1",
   "metadata": {},
   "source": [
    "\n",
    "*   Ti√™u ƒë·ªÅ: N·ªñI ƒêAU KH√îNG C·ª¶A RI√äNG AI\n",
    "*  \n",
    "    T√°c h·∫°i c·ªßa ch·∫•t k√≠ch th√≠ch kh√¥ng ch·ªâ d·ª´ng l·∫°i ·ªü c√° nh√¢n ng∆∞·ªùi s·ª≠ d·ª•ng, m√† c√≤n lan r·ªông nh∆∞ m·ªôt v·∫øt d·∫ßu loang, t√†n ph√° nh·ªØng g√¨ thi√™ng li√™ng nh·∫•t:\n",
    "    *   Gia ƒë√¨nh tan v·ª°: H·∫°nh ph√∫c, b√¨nh y√™n c·ªßa t·ªï ·∫•m b·ªã ph√° h·ªßy\n",
    "    *   M·∫ßm m·ªëng t·ªôi √°c: ƒê·ªÉ c√≥ ti·ªÅn s·ª≠ d·ª•ng ch·∫•t k√≠ch th√≠ch, nhi·ªÅu ng∆∞·ªùi s·∫µn s√†ng ph·∫°m t·ªôi (tr·ªôm c·∫Øp, c∆∞·ªõ[] gi·∫≠t, l·ª´a ƒë·∫£o...). G√¢y m·∫•t an ninh tr·∫≠t t·ª± x√£ h·ªôi.\n",
    "    *   G√°nh n·∫∑ng x√£ h·ªôi: Chi ph√≠ ƒëi·ªÅu tr·ªã, cai nghi·ªán t·ªën k√©m. Ngu·ªìn l·ª±c x√£ h·ªôi b·ªã l√£ng ph√≠. H√¨nh ·∫£nh ƒë·∫•t n∆∞·ªõc, con ng∆∞·ªùi b·ªã ·∫£nh h∆∞·ªüng.\n",
    "    *   M·∫•t ƒëi t∆∞∆°ng lai th·∫ø h·ªá: Khi nh·ªØng ng∆∞·ªùi tr·∫ª sa ng√£, t∆∞∆°ng lai c·ªßa c·∫£ m·ªôt th·∫ø h·ªá b·ªã ƒëe d·ªça.\n",
    "*   **H√¨nh ·∫£nh:** M·ªôt h√¨nh ·∫£nh c·∫£m ƒë·ªông v·ªÅ gia ƒë√¨nh (v√≠ d·ª•: m·ªôt b√†n tay cha m·∫π c·ªë n√≠u gi·ªØ tay con, nh∆∞ng tay con l·∫°i h∆∞·ªõng v·ªÅ m·ªôt th·ª© kh√°c; ho·∫∑c h√¨nh ·∫£nh gia ƒë√¨nh sum v·∫ßy nh∆∞ng c√≥ m·ªôt kho·∫£ng tr·ªëng).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f393d",
   "metadata": {},
   "source": [
    " S·ª≠ d·ª•ng ch·∫•t k√≠ch th√≠ch l√† c√°nh c·ª≠a d·∫´n ƒë·∫øn nh·ªØng bi k·ªãch kh√¥ng ai mong mu·ªën, h·ªßy ho·∫°i t·ª´ng ph·∫ßn cu·ªôc s·ªëng c·ªßa b·∫°n:\n",
    "    *   S·ª©c kh·ªèe tan t√†nh: Gan, th·∫≠n, tim, ph·ªïi... t·∫•t c·∫£ ƒë·ªÅu b·ªã t√†n ph√°. H·ªá mi·ªÖn d·ªãch suy y·∫øu, nguy c∆° m·∫Øc c√°c b·ªánh truy·ªÅn nhi·ªÖm (HIV/AIDS, vi√™m gan B, C) tƒÉng cao.\n",
    "    *   T√¢m tr√≠ u t·ªëi: G√¢y r·ªëi lo·∫°n t√¢m th·∫ßn, tr·∫ßm c·∫£m, lo √¢u, ·∫£o gi√°c, m·∫•t ki·ªÉm so√°t h√†nh vi. B·∫°n kh√¥ng c√≤n l√† ch√≠nh m√¨nh, m√† b·ªã ƒëi·ªÅu khi·ªÉn b·ªüi ch·∫•t g√¢y nghi·ªán.\n",
    "    *   T√†i ch√≠nh ki·ªát qu·ªá: Ti·ªÅn b·∫°c ƒë·ªôi n√≥n ra ƒëi nhanh ch√≥ng ƒë·ªÉ th·ªèa m√£n c∆°n nghi·ªán, d·∫´n ƒë·∫øn n·ª£ n·∫ßn, tr·ªôm c·∫Øp, b√°n r·∫ª danh d·ª±.\n",
    "    *   M·∫•t ƒëi ch√≠nh m√¨nh: T·ª´ m·ªôt ng∆∞·ªùi c√≥ ∆∞·ªõc m∆°, ho√†i b√£o, b·∫°n tr·ªü th√†nh n√¥ l·ªá c·ªßa ch·∫•t k√≠ch th√≠ch, ƒë√°nh m·∫•t gi√° tr·ªã b·∫£n th√¢n, s·ª± t·ª± tr·ªçng v√† ni·ªÅm tin c·ªßa m·ªçi ng∆∞·ªùi.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a70a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ThucChienTextGenerator:\n",
    "   \"\"\"Client sinh vƒÉn b·∫£n qua gateway AI Th·ª±c Chi·∫øn (chu·∫©n OpenAI + Gemini compatible).\"\"\"\n",
    "\n",
    "\n",
    "   def __init__(self,\n",
    "                base_url: str = \"https://api.thucchien.ai\",\n",
    "                api_key: Optional[str] = None,\n",
    "                debug: bool = False):\n",
    "       self.base_url = base_url.rstrip(\"/\")\n",
    "       self.api_key = api_key or os.getenv(\"LITELLM_API_KEY\", \"\")\n",
    "       self.debug = debug\n",
    "       self.headers = {\n",
    "           \"Content-Type\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "       }\n",
    "\n",
    "\n",
    "   def generate_text(self,\n",
    "                     prompt: str,\n",
    "                     model: str = \"gemini-2.5-flash\",\n",
    "                     system_prompt: str = \"You are a helpful AI assistant.\",\n",
    "                     temperature: float = 0.7,\n",
    "                     max_tokens: int = 4096) -> Optional[str]:\n",
    "       \"\"\"\n",
    "       Sinh vƒÉn b·∫£n b·∫±ng m√¥ h√¨nh AI Th·ª±c Chi·∫øn (t·ª± ƒë·ªông nh·∫≠n d·∫°ng c·∫•u tr√∫c JSON ph·∫£n h·ªìi).\n",
    "\n",
    "\n",
    "       Args:\n",
    "           prompt: n·ªôi dung y√™u c·∫ßu sinh vƒÉn b·∫£n\n",
    "           model: model c·∫ßn d√πng (vd: gemini-2.5-flash, gemini-2.0-pro, mistral, claude)\n",
    "           system_prompt: h∆∞·ªõng d·∫´n cho model\n",
    "           temperature: ƒë·ªô s√°ng t·∫°o (0‚Äì1)\n",
    "           max_tokens: s·ªë token t·ªëi ƒëa\n",
    "       \"\"\"\n",
    "       url = f\"{self.base_url}/chat/completions\"\n",
    "\n",
    "\n",
    "       payload = {\n",
    "           \"model\": model,\n",
    "           \"temperature\": temperature,\n",
    "           \"max_tokens\": max_tokens,\n",
    "           \"messages\": [\n",
    "               {\"role\": \"system\", \"content\": system_prompt},\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ]\n",
    "       }\n",
    "\n",
    "\n",
    "       print(f\"üß† Generating text using model: {model} ...\")\n",
    "\n",
    "\n",
    "       try:\n",
    "           response = requests.post(url, headers=self.headers, data=json.dumps(payload))\n",
    "           response.raise_for_status()\n",
    "           data = response.json()\n",
    "\n",
    "\n",
    "           if self.debug:\n",
    "               print(\"\\n--- RAW RESPONSE ---\")\n",
    "               print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "               print(\"--------------------\\n\")\n",
    "\n",
    "\n",
    "           text_output = None\n",
    "\n",
    "\n",
    "           # ‚úÖ 1. Chu·∫©n OpenAI\n",
    "           if \"choices\" in data:\n",
    "               choice = data[\"choices\"][0]\n",
    "               if \"message\" in choice and \"content\" in choice[\"message\"]:\n",
    "                   text_output = choice[\"message\"][\"content\"]\n",
    "               elif \"delta\" in choice and \"content\" in choice[\"delta\"]:\n",
    "                   text_output = choice[\"delta\"][\"content\"]\n",
    "\n",
    "\n",
    "           # ‚úÖ 2. Chu·∫©n Gemini API\n",
    "           elif \"candidates\" in data:\n",
    "               candidate = data[\"candidates\"][0]\n",
    "               if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n",
    "                   text_output = candidate[\"content\"][\"parts\"][0].get(\"text\", \"\")\n",
    "               elif \"output_text\" in candidate:\n",
    "                   text_output = candidate[\"output_text\"]\n",
    "\n",
    "\n",
    "           # ‚úÖ 3. Chu·∫©n LiteLLM proxy\n",
    "           elif \"output_text\" in data:\n",
    "               text_output = data[\"output_text\"]\n",
    "\n",
    "\n",
    "           # ‚úÖ Kh√¥ng c√≥ n·ªôi dung h·ª£p l·ªá\n",
    "           if not text_output:\n",
    "               print(\"‚ö†Ô∏è Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung t·ª´ ph·∫£n h·ªìi:\")\n",
    "               print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "               return None\n",
    "\n",
    "\n",
    "           print(\"‚úÖ Text generation complete!\\n\")\n",
    "           return text_output.strip()\n",
    "\n",
    "\n",
    "       except requests.RequestException as e:\n",
    "           print(f\"‚ùå Request failed: {e}\")\n",
    "           if e.response is not None:\n",
    "               try:\n",
    "                   print(json.dumps(e.response.json(), indent=2))\n",
    "               except:\n",
    "                   print(e.response.text)\n",
    "           return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================== MAIN ======================\n",
    "def main():\n",
    "   base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai\")\n",
    "   api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-JJytUYWGmr5BGv9rVurb2Q\")\n",
    "\n",
    "\n",
    "   generator = ThucChienTextGenerator(base_url=base_url, api_key=api_key, debug=False)\n",
    "\n",
    "\n",
    "   prompt = \"\"\" B·∫°n l√† m·ªôt nh√† thi·∫øt k·∫ø t√†i ba, h√£y t·∫°o cho t√¥i n·ªôi dung c·ªßa t·ªù flyer k√≠ch c·ª° A4 g·∫•p ba (10x21cm m·ªôt m·∫£nh) ch·ªß ƒë·ªÅ tuy√™n truy·ªÅn n√¢ng cao nh·∫≠n th·ª©c v·ªÅ t√°c h·∫°i, h·∫≠u qu·∫£ c·ªßa ch·∫•t k√≠ch th√≠ch (nh∆∞ ma tu√Ω, r∆∞·ª£u bia...) cho c·ªông ƒë·ªìng t·∫°i c√°c ƒëi·ªÉm du l·ªãch, b·ªánh vi·ªán, n∆°i c√¥ng c·ªông.T·ªù g·∫•p n√†y s·∫Ω ƒë∆∞·ª£c ph√°t t·∫°i c√°c ƒëi·ªÉm c√¥ng c·ªông, b·ªánh vi·ªán l·ªõn, ƒëi·ªÉm du l·ªãch, kh√°ch s·∫°n trong chi·∫øn d·ªãch truy·ªÅn th√¥ng c·ªông ƒë·ªìng ph√≤ng, ch·ªëng ch·∫•t k√≠ch th√≠ch nƒÉm 2025. N·ªôi dung c·∫ßn ch√∫ tr·ªçng l√† Vi·ªác s·ª≠ d·ª•ng c√°c ch·∫•t k√≠ch th√≠ch (ma tu√Ω, r∆∞·ª£u bia, ‚Ä¶) d·∫´n t·ªõi nhi·ªÅu h·ªá qu·∫£ ti√™u c·ª±c ƒë·ªëi v·ªõi c√° nh√¢n v√† c·ªông ƒë·ªìng, c·∫ßn s√°ng t·∫°o n·ªôi dung g·∫ßn g≈©i, c·∫£m x√∫c, truy·ªÅn c·∫£m h·ª©ng ƒë·ªÉ gi√°o d·ª•c, c·∫£nh b√°o, ph√≤ng ng·ª´a.\"\"\"\n",
    "\n",
    "\n",
    "   result = generator.generate_text(\n",
    "       prompt=prompt,\n",
    "       model=\"gemini-2.5-flash\",\n",
    "       system_prompt=\"B·∫°n l√† m·ªôt nh√† thi·∫øt k·∫ø n·ªôi dung t√†i ba\"\n",
    "   )\n",
    "\n",
    "\n",
    "   if result:\n",
    "       print(\"üìú K·∫øt qu·∫£ sinh vƒÉn b·∫£n:\\n\")\n",
    "       print(result)\n",
    "   else:\n",
    "       print(\"‚ùå Kh√¥ng sinh ƒë∆∞·ª£c vƒÉn b·∫£n.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc5dbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Generating text using model: gemini-2.5-flash ...\n",
      "‚úÖ Text generation complete!\n",
      "\n",
      "üìú K·∫øt qu·∫£ sinh vƒÉn b·∫£n:\n",
      "\n",
      "Ch√†o b·∫°n, v·ªõi vai tr√≤ l√† m·ªôt nh√† thi·∫øt k·∫ø n·ªôi dung, t√¥i r·∫•t s·∫µn l√≤ng t·ªïng h·ª£p th√¥ng tin v·ªÅ th·ª±c tr·∫°ng s·ª≠ d·ª•ng ch·∫•t k√≠ch th√≠ch t·∫°i Vi·ªát Nam, ƒë·∫∑c bi·ªát trong gi·ªõi tr·∫ª.\n",
      "\n",
      "Tuy nhi√™n, c√≥ m·ªôt ƒëi·ªÉm c·∫ßn l∆∞u √Ω quan tr·ªçng: **th√¥ng tin m·ªõi nh·∫•t nƒÉm 2025 l√† ƒëi·ªÅu kh√¥ng th·ªÉ c√≥ ƒë∆∞·ª£c v√†o th·ªùi ƒëi·ªÉm hi·ªán t·∫°i (cu·ªëi nƒÉm 2023 / ƒë·∫ßu nƒÉm 2024)**. C√°c b√°o c√°o ch√≠nh th·ª©c th∆∞·ªùng c√≥ ƒë·ªô tr·ªÖ nh·∫•t ƒë·ªãnh ƒë·ªÉ t·ªïng h·ª£p v√† ph√¢n t√≠ch d·ªØ li·ªáu. Do ƒë√≥, t√¥i s·∫Ω cung c·∫•p cho b·∫°n nh·ªØng th√¥ng tin c·∫≠p nh·∫≠t nh·∫•t d·ª±a tr√™n c√°c b√°o c√°o, nghi√™n c·ª©u v√† nh·∫≠n ƒë·ªãnh c·ªßa c√°c c∆° quan ch·ª©c nƒÉng Vi·ªát Nam trong giai ƒëo·∫°n g·∫ßn ƒë√¢y nh·∫•t (th∆∞·ªùng l√† 2022-2023 v√† c√°c d·ª± b√°o xu h∆∞·ªõng ti·∫øp theo).\n",
      "\n",
      "D∆∞·ªõi ƒë√¢y l√† ba n·ªôi dung c·ª• th·ªÉ kh√°c nhau v·ªÅ th·ª±c tr·∫°ng n√†y:\n",
      "\n",
      "---\n",
      "\n",
      "### **Th·ª±c Tr·∫°ng S·ª≠ D·ª•ng Ch·∫•t K√≠ch Th√≠ch T·∫°i Vi·ªát Nam (ƒê·∫∑c Bi·ªát Gi·ªõi Tr·∫ª) - C·∫≠p Nh·∫≠t ƒê·∫øn 2023/2024**\n",
      "\n",
      "**1. S·ª± Chuy·ªÉn D·ªãch M·∫°nh M·∫Ω V·ªÅ Lo·∫°i H√¨nh Ma T√∫y v√† Xu H∆∞·ªõng \"Tr·∫ª H√≥a\" Ng∆∞·ªùi Nghi·ªán:**\n",
      "\n",
      "*   **Chuy·ªÉn d·ªãch lo·∫°i h√¨nh:** Th·ª±c tr·∫°ng ƒë√°ng b√°o ƒë·ªông nh·∫•t trong nh·ªØng nƒÉm g·∫ßn ƒë√¢y l√† s·ª± chuy·ªÉn d·ªãch t·ª´ c√°c lo·∫°i ma t√∫y truy·ªÅn th·ªëng (nh∆∞ heroin, thu·ªëc phi·ªán) sang **ma t√∫y t·ªïng h·ª£p (MTS)** v√† c√°c **ch·∫•t h∆∞·ªõng th·∫ßn m·ªõi (NPS)**. C√°c lo·∫°i MTS ph·ªï bi·∫øn bao g·ªìm Methamphetamine (ƒë√°), MDMA (thu·ªëc l·∫Øc), Ketamine, c√πng v·ªõi s·ª± xu·∫•t hi·ªán ng√†y c√†ng nhi·ªÅu c·ªßa c√°c ch·∫•t m·ªõi nh∆∞ \"n∆∞·ªõc vui\", \"b√≥ng c∆∞·ªùi\" (kh√≠ N2O), hay c√°c lo·∫°i ma t√∫y tr√° h√¨nh d∆∞·ªõi d·∫°ng th·ª±c ph·∫©m, ƒë·ªì u·ªëng, thu·ªëc l√° ƒëi·ªán t·ª≠. Nh·ªØng ch·∫•t n√†y th∆∞·ªùng g√¢y ·∫£o gi√°c m·∫°nh, hoang t∆∞·ªüng, lo·∫°n th·∫ßn, v√† c√≥ th·ªÉ d·∫´n ƒë·∫øn h√†nh vi b·∫°o l·ª±c, nguy hi·ªÉm cho b·∫£n th√¢n v√† x√£ h·ªôi.\n",
      "*   **\"Tr·∫ª h√≥a\" ng∆∞·ªùi nghi·ªán:** Gi·ªõi tr·∫ª (d∆∞·ªõi 30 tu·ªïi) ƒëang chi·∫øm t·ª∑ l·ªá ng√†y c√†ng cao trong s·ªë ng∆∞·ªùi s·ª≠ d·ª•ng ma t√∫y, ƒë·∫∑c bi·ªát l√† MTS. C√°c b√°o c√°o cho th·∫•y c√≥ t·ªõi **70-80% s·ªë ng∆∞·ªùi nghi·ªán m·ªõi l√† ng∆∞·ªùi tr·∫ª tu·ªïi**. ƒê·ªô tu·ªïi trung b√¨nh c·ªßa ng∆∞·ªùi s·ª≠ d·ª•ng ma t√∫y ƒëang c√≥ xu h∆∞·ªõng gi·∫£m, th·∫≠m ch√≠ c√≥ nh·ªØng tr∆∞·ªùng h·ª£p ch·ªâ m·ªõi 13-15 tu·ªïi ƒë√£ ti·∫øp x√∫c v√† s·ª≠ d·ª•ng ma t√∫y. ƒê√¢y l√† m·ªëi hi·ªÉm h·ªça l·ªõn ƒë·ªëi v·ªõi t∆∞∆°ng lai c·ªßa ƒë·∫•t n∆∞·ªõc.\n",
      "*   **D·ªÖ ti·∫øp c·∫≠n v√† ƒëa d·∫°ng h√≥a:** Ma t√∫y t·ªïng h·ª£p d·ªÖ d√†ng ƒë∆∞·ª£c s·∫£n xu·∫•t, v·∫≠n chuy·ªÉn v√† c·∫•t gi·∫•u h∆°n. Ch√∫ng ƒë∆∞·ª£c qu·∫£ng c√°o r·∫ßm r·ªô tr√™n m·∫°ng x√£ h·ªôi, len l·ªèi v√†o c√°c m√¥i tr∆∞·ªùng gi·∫£i tr√≠ nh∆∞ qu√°n bar, v≈© tr∆∞·ªùng, karaoke, th·∫≠m ch√≠ c·∫£ c√°c bu·ªïi ti·ªác c√° nh√¢n, l·ªÖ h·ªôi √¢m nh·∫°c. S·ª± ƒëa d·∫°ng v·ªÅ h√¨nh th·ª©c v√† m·∫´u m√£ (vi√™n n√©n, b·ªôt, tinh th·ªÉ, dung d·ªãch) khi·∫øn vi·ªác nh·∫≠n bi·∫øt v√† ki·ªÉm so√°t tr·ªü n√™n kh√≥ khƒÉn h∆°n.\n",
      "\n",
      "**2. Gi·ªõi Tr·∫ª ‚Äì ƒê·ªëi T∆∞·ª£ng D·ªÖ B·ªã T·ªïn Th∆∞∆°ng v√† C√°c Y·∫øu T·ªë Th√∫c ƒê·∫©y:**\n",
      "\n",
      "*   **T√¢m l√Ω t√≤ m√≤ v√† √°p l·ª±c b·∫°n b√®:** Gi·ªõi tr·∫ª th∆∞·ªùng c√≥ t√¢m l√Ω mu·ªën th·ª≠ c√°i m·ªõi, kh√°m ph√° nh·ªØng c·∫£m gi√°c l·∫°. √Åp l·ª±c t·ª´ nh√≥m b·∫°n b√®, mu·ªën ƒë∆∞·ª£c c√¥ng nh·∫≠n, kh√¥ng mu·ªën b·ªã l·∫°c l√µng kh·ªèi c·ªông ƒë·ªìng c≈©ng l√† y·∫øu t·ªë quan tr·ªçng khi·∫øn c√°c em d·ªÖ sa ng√£.\n",
      "*   **Thi·∫øu ki·∫øn th·ª©c v√† k·ªπ nƒÉng t·ª´ ch·ªëi:** Nhi·ªÅu b·∫°n tr·∫ª thi·∫øu ki·∫øn th·ª©c ƒë·∫ßy ƒë·ªß v·ªÅ t√°c h·∫°i kh·ªßng khi·∫øp c·ªßa ma t√∫y, ƒë·∫∑c bi·ªát l√† c√°c lo·∫°i ma t√∫y m·ªõi. K·ªπ nƒÉng t·ª´ ch·ªëi tr∆∞·ªõc l·ªùi m·ªùi g·ªçi, d·ª• d·ªó c·ªßa b·∫°n b√® x·∫•u ho·∫∑c ƒë·ªëi t∆∞·ª£ng bu√¥n b√°n ma t√∫y c√≤n h·∫°n ch·∫ø.\n",
      "*   **M√¥i tr∆∞·ªùng s·ªëng v√† c√°c y·∫øu t·ªë x√£ h·ªôi:** M√¥i tr∆∞·ªùng gia ƒë√¨nh thi·∫øu quan t√¢m, gi√°o d·ª•c l·ªèng l·∫ªo, ho·∫∑c c√°c v·∫•n ƒë·ªÅ t√¢m l√Ω nh∆∞ cƒÉng th·∫≥ng, tr·∫ßm c·∫£m, √°p l·ª±c h·ªçc t·∫≠p, c√¥ng vi·ªác c≈©ng c√≥ th·ªÉ ƒë·∫©y gi·ªõi tr·∫ª t√¨m ƒë·∫øn ma t√∫y nh∆∞ m·ªôt l·ªëi tho√°t t·∫°m th·ªùi. S·ª± ph√°t tri·ªÉn c·ªßa c√¥ng ngh·ªá th√¥ng tin v√† m·∫°ng x√£ h·ªôi c≈©ng t·∫°o ƒëi·ªÅu ki·ªán cho vi·ªác ti·∫øp c·∫≠n th√¥ng tin sai l·ªách ho·∫∑c b·ªã l√¥i k√©o v√†o c√°c nh√≥m s·ª≠ d·ª•ng ma t√∫y.\n",
      "*   **Ma t√∫y tr√° h√¨nh:** ƒê·∫∑c bi·ªát nguy hi·ªÉm l√† xu h∆∞·ªõng ma t√∫y ƒë∆∞·ª£c ng·ª•y trang d∆∞·ªõi d·∫°ng th·ª±c ph·∫©m, ƒë·ªì u·ªëng quen thu·ªôc (b√°nh k·∫πo, n∆∞·ªõc gi·∫£i kh√°t, \"tr√† s·ªØa\", \"n∆∞·ªõc vui\", thu·ªëc l√° ƒëi·ªán t·ª≠ c√≥ t·∫©m ch·∫•t g√¢y nghi·ªán). ƒêi·ªÅu n√†y khi·∫øn gi·ªõi tr·∫ª d·ªÖ d√†ng b·ªã l·ª´a g·∫°t, s·ª≠ d·ª•ng m√† kh√¥ng h·ªÅ hay bi·∫øt m√¨nh ƒëang d√πng ma t√∫y, d·∫´n ƒë·∫øn nghi·ªán l√∫c n√†o kh√¥ng hay.\n",
      "\n",
      "**3. Th√°ch Th·ª©c Trong C√¥ng T√°c Ph√≤ng Ch·ªëng v√† N·ªó L·ª±c C·ªßa Vi·ªát Nam:**\n",
      "\n",
      "*   **Th√°ch th·ª©c l·ªõn:**\n",
      "    *   **T·ªôi ph·∫°m tinh vi, xuy√™n qu·ªëc gia:** C√°c ƒë∆∞·ªùng d√¢y bu√¥n b√°n ma t√∫y ng√†y c√†ng tinh vi, s·ª≠ d·ª•ng c√¥ng ngh·ªá cao, ho·∫°t ƒë·ªông xuy√™n bi√™n gi·ªõi, g√¢y kh√≥ khƒÉn l·ªõn cho c√¥ng t√°c ƒëi·ªÅu tra, b·∫Øt gi·ªØ.\n",
      "    *   **S·ª± xu·∫•t hi·ªán li√™n t·ª•c c·ªßa ma t√∫y m·ªõi:** C√°c ch·∫•t h∆∞·ªõng th·∫ßn m·ªõi li√™n t·ª•c xu·∫•t hi·ªán, nhi·ªÅu lo·∫°i ch∆∞a n·∫±m trong danh m·ª•c ki·ªÉm so√°t, g√¢y kh√≥ khƒÉn cho vi·ªác qu·∫£n l√Ω v√† x·ª≠ l√Ω ph√°p lu·∫≠t.\n",
      "    *   **Kh√≥ khƒÉn trong cai nghi·ªán v√† t√°i h√≤a nh·∫≠p:** T·ª∑ l·ªá t√°i nghi·ªán c√≤n cao, ƒë·∫∑c bi·ªát v·ªõi MTS do t√°c ƒë·ªông s√¢u s·∫Øc ƒë·∫øn th·∫ßn kinh. C√¥ng t√°c cai nghi·ªán, qu·∫£n l√Ω sau cai v√† h·ªó tr·ª£ ng∆∞·ªùi nghi·ªán t√°i h√≤a nh·∫≠p c·ªông ƒë·ªìng c√≤n nhi·ªÅu h·∫°n ch·∫ø v·ªÅ ngu·ªìn l·ª±c v√† ph∆∞∆°ng ph√°p.\n",
      "    *   **Nh·∫≠n th·ª©c c·ªông ƒë·ªìng c√≤n h·∫°n ch·∫ø:** M·ªôt b·ªô ph·∫≠n ng∆∞·ªùi d√¢n, ƒë·∫∑c bi·ªát l√† ph·ª• huynh, v·∫´n ch∆∞a nh·∫≠n th·ª©c ƒë·∫ßy ƒë·ªß v·ªÅ s·ª± nguy hi·ªÉm v√† c√°c d·∫•u hi·ªáu c·ªßa vi·ªác s·ª≠ d·ª•ng ma t√∫y, ƒë·∫∑c bi·ªát l√† ma t√∫y tr√° h√¨nh.\n",
      "*   **N·ªó l·ª±c c·ªßa Vi·ªát Nam:**\n",
      "    *   **TƒÉng c∆∞·ªùng ƒë·∫•u tranh, tr·∫•n √°p:** C√°c l·ª±c l∆∞·ª£ng ch·ª©c nƒÉng (C√¥ng an, B·ªô ƒë·ªôi Bi√™n ph√≤ng, H·∫£i quan) li√™n t·ª•c m·ªü c√°c ƒë·ª£t cao ƒëi·ªÉm t·∫•n c√¥ng, tr·∫•n √°p t·ªôi ph·∫°m ma t√∫y, tri·ªát ph√° nhi·ªÅu ƒë∆∞·ªùng d√¢y l·ªõn, b·∫Øt gi·ªØ s·ªë l∆∞·ª£ng ma t√∫y k·ª∑ l·ª•c.\n",
      "    *   **Ho√†n thi·ªán ph√°p lu·∫≠t v√† ch√≠nh s√°ch:** Vi·ªát Nam ƒë√£ v√† ƒëang ti·∫øp t·ª•c r√† so√°t, b·ªï sung c√°c quy ƒë·ªãnh ph√°p lu·∫≠t li√™n quan ƒë·∫øn ph√≤ng ch·ªëng ma t√∫y, c·∫≠p nh·∫≠t danh m·ª•c c√°c ch·∫•t ma t√∫y v√† ti·ªÅn ch·∫•t ƒë·ªÉ ph√π h·ª£p v·ªõi t√¨nh h√¨nh th·ª±c t·∫ø.\n",
      "    *   **ƒê·∫©y m·∫°nh tuy√™n truy·ªÅn, gi√°o d·ª•c:** TƒÉng c∆∞·ªùng c√°c ho·∫°t ƒë·ªông tuy√™n truy·ªÅn v·ªÅ t√°c h·∫°i c·ªßa ma t√∫y, ƒë·∫∑c bi·ªát nh·∫Øm v√†o gi·ªõi tr·∫ª th√¥ng qua tr∆∞·ªùng h·ªçc, m·∫°ng x√£ h·ªôi, c√°c chi·∫øn d·ªãch truy·ªÅn th√¥ng c·ªông ƒë·ªìng. Ch√∫ tr·ªçng gi√°o d·ª•c k·ªπ nƒÉng s·ªëng, k·ªπ nƒÉng ph√≤ng tr√°nh ma t√∫y.\n",
      "    *   **ƒê·ªïi m·ªõi c√¥ng t√°c cai nghi·ªán:** Ti·∫øp t·ª•c tri·ªÉn khai c√°c m√¥ h√¨nh cai nghi·ªán hi·ªáu qu·∫£ h∆°n, bao g·ªìm cai nghi·ªán b·∫Øt bu·ªôc, cai nghi·ªán t·ª± nguy·ªán, ƒëi·ªÅu tr·ªã thay th·∫ø b·∫±ng Methadone, v√† tƒÉng c∆∞·ªùng h·ªó tr·ª£ t√°i h√≤a nh·∫≠p c·ªông ƒë·ªìng.\n",
      "    *   **H·ª£p t√°c qu·ªëc t·∫ø:** Ch·ªß ƒë·ªông v√† t√≠ch c·ª±c h·ª£p t√°c v·ªõi c√°c n∆∞·ªõc trong khu v·ª±c v√† qu·ªëc t·∫ø trong ph√≤ng ch·ªëng ma t√∫y, trao ƒë·ªïi th√¥ng tin, kinh nghi·ªám v√† ph·ªëi h·ª£p ƒë·∫•u tranh.\n",
      "\n",
      "---\n",
      "\n",
      "**K·∫øt lu·∫≠n:** Th·ª±c tr·∫°ng s·ª≠ d·ª•ng ch·∫•t k√≠ch th√≠ch t·∫°i Vi·ªát Nam, ƒë·∫∑c bi·ªát trong gi·ªõi tr·∫ª, ƒëang l√† m·ªôt v·∫•n ƒë·ªÅ x√£ h·ªôi nghi√™m tr·ªçng v√† ph·ª©c t·∫°p. S·ª± chuy·ªÉn d·ªãch sang ma t√∫y t·ªïng h·ª£p, xu h∆∞·ªõng tr·∫ª h√≥a ng∆∞·ªùi nghi·ªán v√† c√°c h√¨nh th·ª©c tr√° h√¨nh tinh vi ƒë·∫∑t ra nh·ªØng th√°ch th·ª©c l·ªõn. ƒê·ªÉ ƒë·ªëi ph√≥ hi·ªáu qu·∫£, c·∫ßn c√≥ s·ª± ph·ªëi h·ª£p ƒë·ªìng b·ªô gi·ªØa gia ƒë√¨nh, nh√† tr∆∞·ªùng, x√£ h·ªôi v√† c√°c c∆° quan ch·ª©c nƒÉng, t·∫≠p trung v√†o gi√°o d·ª•c ph√≤ng ng·ª´a, n√¢ng cao nh·∫≠n th·ª©c v√† tƒÉng c∆∞·ªùng c√¥ng t√°c ƒë·∫•u tranh, tr·∫•n √°p t·ªôi ph·∫°m ma t√∫y.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ThucChienTextGenerator:\n",
    "   \"\"\"Client sinh vƒÉn b·∫£n qua gateway AI Th·ª±c Chi·∫øn (chu·∫©n OpenAI + Gemini compatible).\"\"\"\n",
    "\n",
    "\n",
    "   def __init__(self,\n",
    "                base_url: str = \"https://api.thucchien.ai\",\n",
    "                api_key: Optional[str] = None,\n",
    "                debug: bool = False):\n",
    "       self.base_url = base_url.rstrip(\"/\")\n",
    "       self.api_key = api_key or os.getenv(\"LITELLM_API_KEY\", \"\")\n",
    "       self.debug = debug\n",
    "       self.headers = {\n",
    "           \"Content-Type\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "       }\n",
    "\n",
    "\n",
    "   def generate_text(self,\n",
    "                     prompt: str,\n",
    "                     model: str = \"gemini-2.5-flash\",\n",
    "                     system_prompt: str = \"You are a helpful AI assistant.\",\n",
    "                     temperature: float = 0.7,\n",
    "                     max_tokens: int = 4096) -> Optional[str]:\n",
    "       \"\"\"\n",
    "       Sinh vƒÉn b·∫£n b·∫±ng m√¥ h√¨nh AI Th·ª±c Chi·∫øn (t·ª± ƒë·ªông nh·∫≠n d·∫°ng c·∫•u tr√∫c JSON ph·∫£n h·ªìi).\n",
    "\n",
    "\n",
    "       Args:\n",
    "           prompt: n·ªôi dung y√™u c·∫ßu sinh vƒÉn b·∫£n\n",
    "           model: model c·∫ßn d√πng (vd: gemini-2.5-flash, gemini-2.0-pro, mistral, claude)\n",
    "           system_prompt: h∆∞·ªõng d·∫´n cho model\n",
    "           temperature: ƒë·ªô s√°ng t·∫°o (0‚Äì1)\n",
    "           max_tokens: s·ªë token t·ªëi ƒëa\n",
    "       \"\"\"\n",
    "       url = f\"{self.base_url}/chat/completions\"\n",
    "\n",
    "\n",
    "       payload = {\n",
    "           \"model\": model,\n",
    "           \"temperature\": temperature,\n",
    "           \"max_tokens\": max_tokens,\n",
    "           \"messages\": [\n",
    "               {\"role\": \"system\", \"content\": system_prompt},\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ]\n",
    "       }\n",
    "\n",
    "\n",
    "       print(f\"üß† Generating text using model: {model} ...\")\n",
    "\n",
    "\n",
    "       try:\n",
    "           response = requests.post(url, headers=self.headers, data=json.dumps(payload))\n",
    "           response.raise_for_status()\n",
    "           data = response.json()\n",
    "\n",
    "\n",
    "           if self.debug:\n",
    "               print(\"\\n--- RAW RESPONSE ---\")\n",
    "               print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "               print(\"--------------------\\n\")\n",
    "\n",
    "\n",
    "           text_output = None\n",
    "\n",
    "\n",
    "           # ‚úÖ 1. Chu·∫©n OpenAI\n",
    "           if \"choices\" in data:\n",
    "               choice = data[\"choices\"][0]\n",
    "               if \"message\" in choice and \"content\" in choice[\"message\"]:\n",
    "                   text_output = choice[\"message\"][\"content\"]\n",
    "               elif \"delta\" in choice and \"content\" in choice[\"delta\"]:\n",
    "                   text_output = choice[\"delta\"][\"content\"]\n",
    "\n",
    "\n",
    "           # ‚úÖ 2. Chu·∫©n Gemini API\n",
    "           elif \"candidates\" in data:\n",
    "               candidate = data[\"candidates\"][0]\n",
    "               if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n",
    "                   text_output = candidate[\"content\"][\"parts\"][0].get(\"text\", \"\")\n",
    "               elif \"output_text\" in candidate:\n",
    "                   text_output = candidate[\"output_text\"]\n",
    "\n",
    "\n",
    "           # ‚úÖ 3. Chu·∫©n LiteLLM proxy\n",
    "           elif \"output_text\" in data:\n",
    "               text_output = data[\"output_text\"]\n",
    "\n",
    "\n",
    "           # ‚úÖ Kh√¥ng c√≥ n·ªôi dung h·ª£p l·ªá\n",
    "           if not text_output:\n",
    "               print(\"‚ö†Ô∏è Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung t·ª´ ph·∫£n h·ªìi:\")\n",
    "               print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "               return None\n",
    "\n",
    "\n",
    "           print(\"‚úÖ Text generation complete!\\n\")\n",
    "           return text_output.strip()\n",
    "\n",
    "\n",
    "       except requests.RequestException as e:\n",
    "           print(f\"‚ùå Request failed: {e}\")\n",
    "           if e.response is not None:\n",
    "               try:\n",
    "                   print(json.dumps(e.response.json(), indent=2))\n",
    "               except:\n",
    "                   print(e.response.text)\n",
    "           return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================== MAIN ======================\n",
    "def main():\n",
    "   base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai\")\n",
    "   api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-JJytUYWGmr5BGv9rVurb2Q\")\n",
    "\n",
    "\n",
    "   generator = ThucChienTextGenerator(base_url=base_url, api_key=api_key, debug=False)\n",
    "\n",
    "\n",
    "   prompt = \"\"\" \n",
    "B·∫°n t·ªïng h·ª£p cho t√¥i th·ª±c tr·∫°ng s·ª≠ d·ª•ng ch·∫•t k√≠ch th√≠ch t·∫°i Vi·ªát Nam (ƒê·∫∑c bi·ªát l√† gi·ªõi tr·∫ª), n·∫øu c√≥ th·ªÉ th√¨ l·∫•y n·ªôi dung th√¥ng tin m·ªõi nh·∫•t 2025, ba n·ªôi dung c·ª• th·ªÉ kh√°c nhau\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "   result = generator.generate_text(\n",
    "       prompt=prompt,\n",
    "       model=\"gemini-2.5-flash\",\n",
    "       system_prompt=\"B·∫°n l√† m·ªôt nh√† thi·∫øt k·∫ø n·ªôi dung t√†i ba\"\n",
    "   )\n",
    "\n",
    "\n",
    "   if result:\n",
    "       print(\"üìú K·∫øt qu·∫£ sinh vƒÉn b·∫£n:\\n\")\n",
    "       print(result)\n",
    "   else:\n",
    "       print(\"‚ùå Kh√¥ng sinh ƒë∆∞·ª£c vƒÉn b·∫£n.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce6c20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585aebb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Generating image using model: gemini-2.5-flash-image-preview\n",
      "üñãÔ∏è Prompt: \n",
      "       H√£y t·∫°o cho t√¥i m·ªôt h√¨nh ·∫£nh k√≠ch th∆∞·ªõc 10*7cm \n",
      "       Ph·∫ßn g√≥c tr√™n b√™n ph·∫£i (ph·∫ßn nh·ªè h∆°n ph·∫ßn g√≥c d∆∞·ªõi b√™n tr√°i) l√† h√¨nh ·∫£nh m·ªôt gia ƒë√¨nh (cha m·∫π, con c√°i) ƒëang n·∫Øm tay nhau vui v·∫ª ƒëi ch∆°i\n",
      "       Ph·∫ßn g√≥c d∆∞·ªõi b√™n tr√°i l√† h√¨nh ·∫£nh tr·∫Øng ƒëen mi√™u t·∫£ m·ªôt gia ƒë√¨nh tan v·ª° v√¨ ng∆∞·ªùi ch·ªìng nghi·ªán ng·∫≠p\n",
      "       Gi·ªØa hai h√¨nh ·∫£nh l√† m·ªôt v·∫øt x√© r√°ch ch√©o (nh∆∞ x√© ƒë√¥i t·ªù gi·∫•y ·∫•y)\n",
      "       High resolution, photorealistic, 8k.\n",
      "       \n",
      "\n",
      "‚úÖ Image saved successfully: futuristic_city.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ThucChienImageGenerator:\n",
    "   \"\"\"Client sinh h√¨nh ·∫£nh qua gateway AI Th·ª±c Chi·∫øn (chu·∫©n OpenAI / Gemini).\"\"\"\n",
    "\n",
    "\n",
    "   def __init__(self,\n",
    "                base_url: str = \"https://api.thucchien.ai/v1\",\n",
    "                api_key: Optional[str] = None,\n",
    "                debug: bool = False):\n",
    "       self.base_url = base_url.rstrip(\"/\")\n",
    "       self.api_key = api_key or os.getenv(\"LITELLM_API_KEY\", \"\")\n",
    "       self.debug = debug\n",
    "       self.headers = {\n",
    "           \"Content-Type\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "       }\n",
    "\n",
    "\n",
    "   def generate_image(self,\n",
    "                      prompt: str,\n",
    "                      model: str = \"gemini-2.5-flash-image-preview\",\n",
    "                      output_path: str = \"generated_image.png\") -> Optional[str]:\n",
    "       \"\"\"\n",
    "       Sinh ·∫£nh t·ª´ m√¥ t·∫£ vƒÉn b·∫£n (prompt) b·∫±ng model gemini-flash-image-preview.\n",
    "\n",
    "\n",
    "       Args:\n",
    "           prompt: m√¥ t·∫£ h√¨nh ·∫£nh c·∫ßn sinh\n",
    "           model: model d√πng ƒë·ªÉ sinh (vd: gemini-2.5-flash-image-preview)\n",
    "           output_path: n∆°i l∆∞u ·∫£nh k·∫øt qu·∫£\n",
    "       \"\"\"\n",
    "       url = f\"{self.base_url}/chat/completions\"\n",
    "       data = {\n",
    "           \"model\": model,\n",
    "           \"messages\": [\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ]\n",
    "       }\n",
    "\n",
    "\n",
    "       print(f\"üé® Generating image using model: {model}\")\n",
    "       print(f\"üñãÔ∏è Prompt: {prompt}\\n\")\n",
    "\n",
    "\n",
    "       try:\n",
    "           response = requests.post(url, headers=self.headers, data=json.dumps(data))\n",
    "           response.raise_for_status()\n",
    "           result = response.json()\n",
    "\n",
    "\n",
    "           if self.debug:\n",
    "               print(\"\\n--- RAW RESPONSE ---\")\n",
    "               print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "               print(\"--------------------\\n\")\n",
    "\n",
    "\n",
    "           # üß© Tr√≠ch xu·∫•t d·ªØ li·ªáu ·∫£nh base64\n",
    "           base64_string = result['choices'][0]['message']['images'][0]['image_url']['url']\n",
    "\n",
    "\n",
    "           # X·ª≠ l√Ω prefix 'data:image/png;base64,' n·∫øu c√≥\n",
    "           if ',' in base64_string:\n",
    "               _, encoded = base64_string.split(',', 1)\n",
    "           else:\n",
    "               encoded = base64_string\n",
    "\n",
    "\n",
    "           image_data = base64.b64decode(encoded)\n",
    "\n",
    "\n",
    "           # L∆∞u ·∫£nh\n",
    "           with open(output_path, 'wb') as f:\n",
    "               f.write(image_data)\n",
    "\n",
    "\n",
    "           print(f\"‚úÖ Image saved successfully: {output_path}\")\n",
    "           return output_path\n",
    "\n",
    "\n",
    "       except requests.exceptions.RequestException as e:\n",
    "           print(f\"‚ùå Request failed: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "       except (KeyError, IndexError) as e:\n",
    "           print(f\"‚ö†Ô∏è Failed to parse image data from response: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================== MAIN ======================\n",
    "def main():\n",
    "   base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai/v1\")\n",
    "   api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-JJytUYWGmr5BGv9rVurb2Q\")\n",
    "\n",
    "\n",
    "   generator = ThucChienImageGenerator(base_url=base_url, api_key=api_key, debug=False)\n",
    "\n",
    "\n",
    "   prompt = (\n",
    "       \"\"\"\n",
    "Sinh cho t√¥i h√¨nh ·∫£nh ho·∫°t h√¨nh v·ªÅ ch·∫•t g√¢y nghi·ªán, k√≠ch c·ª° 10*\n",
    "       \"\"\"\n",
    "   )\n",
    "\n",
    "\n",
    "   generator.generate_image(prompt, output_path=\"futuristic_city.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fadcf215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Generating image using model: gemini-2.5-flash-image-preview\n",
      "üñãÔ∏è Prompt: \n",
      "    H√£y t·∫°o cho t√¥i h√¨nh ·∫£nh m·ªôt ch√†ng trai tr·∫ª 20 tu·ªïi b·ªã nghi·ªán ma tu√Ω, l√†n da s·∫°m ƒëi, ng∆∞·ªùi g·∫ßy g√≤ ·ªëm y·∫øu, k√≠ch c·ª° 8*6cm\n",
      "\n",
      "\n",
      "‚úÖ Image saved successfully: body.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ThucChienImageGenerator:\n",
    "   \"\"\"Client sinh h√¨nh ·∫£nh qua gateway AI Th·ª±c Chi·∫øn (chu·∫©n OpenAI / Gemini).\"\"\"\n",
    "\n",
    "\n",
    "   def __init__(self,\n",
    "                base_url: str = \"https://api.thucchien.ai/v1\",\n",
    "                api_key: Optional[str] = None,\n",
    "                debug: bool = False):\n",
    "       self.base_url = base_url.rstrip(\"/\")\n",
    "       self.api_key = api_key or os.getenv(\"LITELLM_API_KEY\", \"\")\n",
    "       self.debug = debug\n",
    "       self.headers = {\n",
    "           \"Content-Type\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "       }\n",
    "\n",
    "\n",
    "   def generate_image(self,\n",
    "                      prompt: str,\n",
    "                      model: str = \"gemini-2.5-flash-image-preview\",\n",
    "                      output_path: str = \"generated_image.png\") -> Optional[str]:\n",
    "       \"\"\"\n",
    "       Sinh ·∫£nh t·ª´ m√¥ t·∫£ vƒÉn b·∫£n (prompt) b·∫±ng model gemini-flash-image-preview.\n",
    "\n",
    "\n",
    "       Args:\n",
    "           prompt: m√¥ t·∫£ h√¨nh ·∫£nh c·∫ßn sinh\n",
    "           model: model d√πng ƒë·ªÉ sinh (vd: gemini-2.5-flash-image-preview)\n",
    "           output_path: n∆°i l∆∞u ·∫£nh k·∫øt qu·∫£\n",
    "       \"\"\"\n",
    "       url = f\"{self.base_url}/chat/completions\"\n",
    "       data = {\n",
    "           \"model\": model,\n",
    "           \"messages\": [\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ]\n",
    "       }\n",
    "\n",
    "\n",
    "       print(f\"üé® Generating image using model: {model}\")\n",
    "       print(f\"üñãÔ∏è Prompt: {prompt}\\n\")\n",
    "\n",
    "\n",
    "       try:\n",
    "           response = requests.post(url, headers=self.headers, data=json.dumps(data))\n",
    "           response.raise_for_status()\n",
    "           result = response.json()\n",
    "\n",
    "\n",
    "           if self.debug:\n",
    "               print(\"\\n--- RAW RESPONSE ---\")\n",
    "               print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "               print(\"--------------------\\n\")\n",
    "\n",
    "\n",
    "           # üß© Tr√≠ch xu·∫•t d·ªØ li·ªáu ·∫£nh base64\n",
    "           base64_string = result['choices'][0]['message']['images'][0]['image_url']['url']\n",
    "\n",
    "\n",
    "           # X·ª≠ l√Ω prefix 'data:image/png;base64,' n·∫øu c√≥\n",
    "           if ',' in base64_string:\n",
    "               _, encoded = base64_string.split(',', 1)\n",
    "           else:\n",
    "               encoded = base64_string\n",
    "\n",
    "\n",
    "           image_data = base64.b64decode(encoded)\n",
    "\n",
    "\n",
    "           # L∆∞u ·∫£nh\n",
    "           with open(output_path, 'wb') as f:\n",
    "               f.write(image_data)\n",
    "\n",
    "\n",
    "           print(f\"‚úÖ Image saved successfully: {output_path}\")\n",
    "           return output_path\n",
    "\n",
    "\n",
    "       except requests.exceptions.RequestException as e:\n",
    "           print(f\"‚ùå Request failed: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "       except (KeyError, IndexError) as e:\n",
    "           print(f\"‚ö†Ô∏è Failed to parse image data from response: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================== MAIN ======================\n",
    "def main():\n",
    "   base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai/v1\")\n",
    "   api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-JJytUYWGmr5BGv9rVurb2Q\")\n",
    "\n",
    "\n",
    "   generator = ThucChienImageGenerator(base_url=base_url, api_key=api_key, debug=False)\n",
    "\n",
    "\n",
    "   prompt = (\"\"\"\n",
    "    H√£y t·∫°o cho t√¥i h√¨nh ·∫£nh m·ªôt ch√†ng trai tr·∫ª 20 tu·ªïi b·ªã nghi·ªán ma tu√Ω, l√†n da s·∫°m ƒëi, ng∆∞·ªùi g·∫ßy g√≤ ·ªëm y·∫øu, k√≠ch c·ª° 8*6cm\n",
    "\"\"\"\n",
    "   )\n",
    "\n",
    "\n",
    "   generator.generate_image(prompt, output_path=\"body.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49e64a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Generating image using model: gemini-2.5-flash-image-preview\n",
      "üñãÔ∏è Prompt: \n",
      "    M·ªôt h√¨nh ·∫£nh c·∫£m ƒë·ªông v·ªÅ gia ƒë√¨nh ( m·ªôt b√†n tay cha m·∫π c·ªë n√≠u gi·ªØ tay con, nh∆∞ng tay con l·∫°i h∆∞·ªõng v·ªÅ m·ªôt th·ª© kh√°c (ma tu√Ω, ch·∫•t k√≠ch th√≠ch,..), k√≠ch c·ª° 8*6cm\n",
      "             \n",
      "\n",
      "‚úÖ Image saved successfully: hand.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ThucChienImageGenerator:\n",
    "   \"\"\"Client sinh h√¨nh ·∫£nh qua gateway AI Th·ª±c Chi·∫øn (chu·∫©n OpenAI / Gemini).\"\"\"\n",
    "\n",
    "\n",
    "   def __init__(self,\n",
    "                base_url: str = \"https://api.thucchien.ai/v1\",\n",
    "                api_key: Optional[str] = None,\n",
    "                debug: bool = False):\n",
    "       self.base_url = base_url.rstrip(\"/\")\n",
    "       self.api_key = api_key or os.getenv(\"LITELLM_API_KEY\", \"\")\n",
    "       self.debug = debug\n",
    "       self.headers = {\n",
    "           \"Content-Type\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "       }\n",
    "\n",
    "\n",
    "   def generate_image(self,\n",
    "                      prompt: str,\n",
    "                      model: str = \"gemini-2.5-flash-image-preview\",\n",
    "                      output_path: str = \"generated_image.png\") -> Optional[str]:\n",
    "       \"\"\"\n",
    "       Sinh ·∫£nh t·ª´ m√¥ t·∫£ vƒÉn b·∫£n (prompt) b·∫±ng model gemini-flash-image-preview.\n",
    "\n",
    "\n",
    "       Args:\n",
    "           prompt: m√¥ t·∫£ h√¨nh ·∫£nh c·∫ßn sinh\n",
    "           model: model d√πng ƒë·ªÉ sinh (vd: gemini-2.5-flash-image-preview)\n",
    "           output_path: n∆°i l∆∞u ·∫£nh k·∫øt qu·∫£\n",
    "       \"\"\"\n",
    "       url = f\"{self.base_url}/chat/completions\"\n",
    "       data = {\n",
    "           \"model\": model,\n",
    "           \"messages\": [\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ]\n",
    "       }\n",
    "\n",
    "\n",
    "       print(f\"üé® Generating image using model: {model}\")\n",
    "       print(f\"üñãÔ∏è Prompt: {prompt}\\n\")\n",
    "\n",
    "\n",
    "       try:\n",
    "           response = requests.post(url, headers=self.headers, data=json.dumps(data))\n",
    "           response.raise_for_status()\n",
    "           result = response.json()\n",
    "\n",
    "\n",
    "           if self.debug:\n",
    "               print(\"\\n--- RAW RESPONSE ---\")\n",
    "               print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "               print(\"--------------------\\n\")\n",
    "\n",
    "\n",
    "           # üß© Tr√≠ch xu·∫•t d·ªØ li·ªáu ·∫£nh base64\n",
    "           base64_string = result['choices'][0]['message']['images'][0]['image_url']['url']\n",
    "\n",
    "\n",
    "           # X·ª≠ l√Ω prefix 'data:image/png;base64,' n·∫øu c√≥\n",
    "           if ',' in base64_string:\n",
    "               _, encoded = base64_string.split(',', 1)\n",
    "           else:\n",
    "               encoded = base64_string\n",
    "\n",
    "\n",
    "           image_data = base64.b64decode(encoded)\n",
    "\n",
    "\n",
    "           # L∆∞u ·∫£nh\n",
    "           with open(output_path, 'wb') as f:\n",
    "               f.write(image_data)\n",
    "\n",
    "\n",
    "           print(f\"‚úÖ Image saved successfully: {output_path}\")\n",
    "           return output_path\n",
    "\n",
    "\n",
    "       except requests.exceptions.RequestException as e:\n",
    "           print(f\"‚ùå Request failed: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "       except (KeyError, IndexError) as e:\n",
    "           print(f\"‚ö†Ô∏è Failed to parse image data from response: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================== MAIN ======================\n",
    "def main():\n",
    "   base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai/v1\")\n",
    "   api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-JJytUYWGmr5BGv9rVurb2Q\")\n",
    "\n",
    "\n",
    "   generator = ThucChienImageGenerator(base_url=base_url, api_key=api_key, debug=False)\n",
    "\n",
    "\n",
    "   prompt = (\"\"\"\n",
    "    M·ªôt h√¨nh ·∫£nh c·∫£m ƒë·ªông v·ªÅ gia ƒë√¨nh ( m·ªôt b√†n tay cha m·∫π c·ªë n√≠u gi·ªØ tay con, nh∆∞ng tay con l·∫°i h∆∞·ªõng v·ªÅ m·ªôt th·ª© kh√°c (ma tu√Ω, ch·∫•t k√≠ch th√≠ch,..), k√≠ch c·ª° 8*6cm\n",
    "             \"\"\"\n",
    "   )\n",
    "\n",
    "\n",
    "   generator.generate_image(prompt, output_path=\"hand.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "343e5812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Generating image using model: gemini-2.5-flash-image-preview\n",
      "üñãÔ∏è Prompt: \n",
      "    m·ªôt ng∆∞·ªùi tr·∫ª ƒëang v∆∞∆°n tay ƒë√≥n √°nh n·∫Øng m·∫∑t tr·ªùi, m·ªôt con ƒë∆∞·ªùng xanh m√°t d·∫´n ƒë·∫øn ch√¢n tr·ªùi, ƒë·ª´ng c√≥ ho·∫°t h√¨nh,c√°i color theme c·ªßa t√¥i ƒëang l√† m√†u ƒë·ªè n√™n c·∫ßn ·∫£nh n√†o fit v·ªõi n√≥, n·∫øu n√≥ l√† xanh l√° th√¨ ki·ªÉu b·ªã t∆∞∆°ng ph·∫£n ·∫•y, kh√¥ng ho·∫°t h√¨nh \n",
      "             \n",
      "\n",
      "‚úÖ Image saved successfully: sun.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ThucChienImageGenerator:\n",
    "   \"\"\"Client sinh h√¨nh ·∫£nh qua gateway AI Th·ª±c Chi·∫øn (chu·∫©n OpenAI / Gemini).\"\"\"\n",
    "\n",
    "\n",
    "   def __init__(self,\n",
    "                base_url: str = \"https://api.thucchien.ai/v1\",\n",
    "                api_key: Optional[str] = None,\n",
    "                debug: bool = False):\n",
    "       self.base_url = base_url.rstrip(\"/\")\n",
    "       self.api_key = api_key or os.getenv(\"LITELLM_API_KEY\", \"\")\n",
    "       self.debug = debug\n",
    "       self.headers = {\n",
    "           \"Content-Type\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "       }\n",
    "\n",
    "\n",
    "   def generate_image(self,\n",
    "                      prompt: str,\n",
    "                      model: str = \"gemini-2.5-flash-image-preview\",\n",
    "                      output_path: str = \"generated_image.png\") -> Optional[str]:\n",
    "       \"\"\"\n",
    "       Sinh ·∫£nh t·ª´ m√¥ t·∫£ vƒÉn b·∫£n (prompt) b·∫±ng model gemini-flash-image-preview.\n",
    "\n",
    "\n",
    "       Args:\n",
    "           prompt: m√¥ t·∫£ h√¨nh ·∫£nh c·∫ßn sinh\n",
    "           model: model d√πng ƒë·ªÉ sinh (vd: gemini-2.5-flash-image-preview)\n",
    "           output_path: n∆°i l∆∞u ·∫£nh k·∫øt qu·∫£\n",
    "       \"\"\"\n",
    "       url = f\"{self.base_url}/chat/completions\"\n",
    "       data = {\n",
    "           \"model\": model,\n",
    "           \"messages\": [\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ]\n",
    "       }\n",
    "\n",
    "\n",
    "       print(f\"üé® Generating image using model: {model}\")\n",
    "       print(f\"üñãÔ∏è Prompt: {prompt}\\n\")\n",
    "\n",
    "\n",
    "       try:\n",
    "           response = requests.post(url, headers=self.headers, data=json.dumps(data))\n",
    "           response.raise_for_status()\n",
    "           result = response.json()\n",
    "\n",
    "\n",
    "           if self.debug:\n",
    "               print(\"\\n--- RAW RESPONSE ---\")\n",
    "               print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "               print(\"--------------------\\n\")\n",
    "\n",
    "\n",
    "           # üß© Tr√≠ch xu·∫•t d·ªØ li·ªáu ·∫£nh base64\n",
    "           base64_string = result['choices'][0]['message']['images'][0]['image_url']['url']\n",
    "\n",
    "\n",
    "           # X·ª≠ l√Ω prefix 'data:image/png;base64,' n·∫øu c√≥\n",
    "           if ',' in base64_string:\n",
    "               _, encoded = base64_string.split(',', 1)\n",
    "           else:\n",
    "               encoded = base64_string\n",
    "\n",
    "\n",
    "           image_data = base64.b64decode(encoded)\n",
    "\n",
    "\n",
    "           # L∆∞u ·∫£nh\n",
    "           with open(output_path, 'wb') as f:\n",
    "               f.write(image_data)\n",
    "\n",
    "\n",
    "           print(f\"‚úÖ Image saved successfully: {output_path}\")\n",
    "           return output_path\n",
    "\n",
    "\n",
    "       except requests.exceptions.RequestException as e:\n",
    "           print(f\"‚ùå Request failed: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "       except (KeyError, IndexError) as e:\n",
    "           print(f\"‚ö†Ô∏è Failed to parse image data from response: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================== MAIN ======================\n",
    "def main():\n",
    "   base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai/v1\")\n",
    "   api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-JJytUYWGmr5BGv9rVurb2Q\")\n",
    "\n",
    "\n",
    "   generator = ThucChienImageGenerator(base_url=base_url, api_key=api_key, debug=False)\n",
    "\n",
    "\n",
    "   prompt = (\"\"\"\n",
    "    m·ªôt ng∆∞·ªùi tr·∫ª ƒëang v∆∞∆°n tay ƒë√≥n √°nh n·∫Øng m·∫∑t tr·ªùi, m·ªôt con ƒë∆∞·ªùng xanh m√°t d·∫´n ƒë·∫øn ch√¢n tr·ªùi, ƒë·ª´ng c√≥ ho·∫°t h√¨nh,c√°i color theme c·ªßa t√¥i ƒëang l√† m√†u ƒë·ªè n√™n c·∫ßn ·∫£nh n√†o fit v·ªõi n√≥, n·∫øu n√≥ l√† xanh l√° th√¨ ki·ªÉu b·ªã t∆∞∆°ng ph·∫£n ·∫•y, kh√¥ng ho·∫°t h√¨nh \n",
    "             \"\"\"\n",
    "   )\n",
    "\n",
    "\n",
    "   generator.generate_image(prompt, output_path=\"sun.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef8c64c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Generating image using model: gemini-2.5-flash-image-preview\n",
      "üñãÔ∏è Prompt: \n",
      "    H√£y t·∫°o m·ªôt ·∫£nh k√≠ch th∆∞·ªõc 10*21 th·ªÉ hi·ªán t∆∞∆°ng lai t∆∞∆°i s√°ng c·ªßa m·ªôt gia ƒë√¨nh khi kh√¥ng d√≠nh ƒë·∫øn ch·∫•t k√≠ch th√≠ch, ƒë·ª´ng c√≥ l·ªìng ch·ªØ g√¨ h·∫øt, n·ªÅn l√†m sao ƒë·ªÉ v·∫´n ƒë·ªß ch√¨m ƒë·ªÉ n√≥ l√†m n·ªÅn cho t√¥i ch√®n ch·ªØ, nh∆∞ng ƒë·ª´ng nh√¨n th·∫•y m·∫∑t ng∆∞·ªùi, ki·ªÉu panel cu·ªëi c·ªßa flyer ·∫•y, d√†i ra \n",
      "             \n",
      "\n",
      "‚úÖ Image saved successfully: end.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ThucChienImageGenerator:\n",
    "   \"\"\"Client sinh h√¨nh ·∫£nh qua gateway AI Th·ª±c Chi·∫øn (chu·∫©n OpenAI / Gemini).\"\"\"\n",
    "\n",
    "\n",
    "   def __init__(self,\n",
    "                base_url: str = \"https://api.thucchien.ai/v1\",\n",
    "                api_key: Optional[str] = None,\n",
    "                debug: bool = False):\n",
    "       self.base_url = base_url.rstrip(\"/\")\n",
    "       self.api_key = api_key or os.getenv(\"LITELLM_API_KEY\", \"\")\n",
    "       self.debug = debug\n",
    "       self.headers = {\n",
    "           \"Content-Type\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "       }\n",
    "\n",
    "\n",
    "   def generate_image(self,\n",
    "                      prompt: str,\n",
    "                      model: str = \"gemini-2.5-flash-image-preview\",\n",
    "                      output_path: str = \"generated_image.png\") -> Optional[str]:\n",
    "       \"\"\"\n",
    "       Sinh ·∫£nh t·ª´ m√¥ t·∫£ vƒÉn b·∫£n (prompt) b·∫±ng model gemini-flash-image-preview.\n",
    "\n",
    "\n",
    "       Args:\n",
    "           prompt: m√¥ t·∫£ h√¨nh ·∫£nh c·∫ßn sinh\n",
    "           model: model d√πng ƒë·ªÉ sinh (vd: gemini-2.5-flash-image-preview)\n",
    "           output_path: n∆°i l∆∞u ·∫£nh k·∫øt qu·∫£\n",
    "       \"\"\"\n",
    "       url = f\"{self.base_url}/chat/completions\"\n",
    "       data = {\n",
    "           \"model\": model,\n",
    "           \"messages\": [\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ]\n",
    "       }\n",
    "\n",
    "\n",
    "       print(f\"üé® Generating image using model: {model}\")\n",
    "       print(f\"üñãÔ∏è Prompt: {prompt}\\n\")\n",
    "\n",
    "\n",
    "       try:\n",
    "           response = requests.post(url, headers=self.headers, data=json.dumps(data))\n",
    "           response.raise_for_status()\n",
    "           result = response.json()\n",
    "\n",
    "\n",
    "           if self.debug:\n",
    "               print(\"\\n--- RAW RESPONSE ---\")\n",
    "               print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "               print(\"--------------------\\n\")\n",
    "\n",
    "\n",
    "           # üß© Tr√≠ch xu·∫•t d·ªØ li·ªáu ·∫£nh base64\n",
    "           base64_string = result['choices'][0]['message']['images'][0]['image_url']['url']\n",
    "\n",
    "\n",
    "           # X·ª≠ l√Ω prefix 'data:image/png;base64,' n·∫øu c√≥\n",
    "           if ',' in base64_string:\n",
    "               _, encoded = base64_string.split(',', 1)\n",
    "           else:\n",
    "               encoded = base64_string\n",
    "\n",
    "\n",
    "           image_data = base64.b64decode(encoded)\n",
    "\n",
    "\n",
    "           # L∆∞u ·∫£nh\n",
    "           with open(output_path, 'wb') as f:\n",
    "               f.write(image_data)\n",
    "\n",
    "\n",
    "           print(f\"‚úÖ Image saved successfully: {output_path}\")\n",
    "           return output_path\n",
    "\n",
    "\n",
    "       except requests.exceptions.RequestException as e:\n",
    "           print(f\"‚ùå Request failed: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "       except (KeyError, IndexError) as e:\n",
    "           print(f\"‚ö†Ô∏è Failed to parse image data from response: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================== MAIN ======================\n",
    "def main():\n",
    "   base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai/v1\")\n",
    "   api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-JJytUYWGmr5BGv9rVurb2Q\")\n",
    "\n",
    "\n",
    "   generator = ThucChienImageGenerator(base_url=base_url, api_key=api_key, debug=False)\n",
    "\n",
    "\n",
    "   prompt = (\"\"\"\n",
    "    H√£y t·∫°o m·ªôt ·∫£nh k√≠ch th∆∞·ªõc 10*21 th·ªÉ hi·ªán t∆∞∆°ng lai t∆∞∆°i s√°ng c·ªßa m·ªôt gia ƒë√¨nh khi kh√¥ng d√≠nh ƒë·∫øn ch·∫•t k√≠ch th√≠ch, ƒë·ª´ng c√≥ l·ªìng ch·ªØ g√¨ h·∫øt, n·ªÅn l√†m sao ƒë·ªÉ v·∫´n ƒë·ªß ch√¨m ƒë·ªÉ n√≥ l√†m n·ªÅn cho t√¥i ch√®n ch·ªØ, nh∆∞ng ƒë·ª´ng nh√¨n th·∫•y m·∫∑t ng∆∞·ªùi, ki·ªÉu panel cu·ªëi c·ªßa flyer ·∫•y, d√†i ra \n",
    "             \"\"\"\n",
    "   )\n",
    "\n",
    "\n",
    "   generator.generate_image(prompt, output_path=\"end.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df4b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
