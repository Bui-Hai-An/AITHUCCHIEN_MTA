{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e374705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Generating image using model: gemini-2.5-flash-image-preview\n",
      "üñãÔ∏è Prompt: H√£y t·∫°o cho t√¥i m·ªôt h√¨nh ·∫£nh k√≠ch th∆∞·ªõc 10*7cm \n",
      "       Ph·∫ßn g√≥c tr√™n b√™n ph·∫£i (ph·∫ßn nh·ªè h∆°n ph·∫ßn g√≥c d∆∞·ªõi b√™n tr√°i) l√† h√¨nh ·∫£nh m·ªôt gia ƒë√¨nh (cha m·∫π, con c√°i) ƒëang n·∫Øm tay nhau vui v·∫ª ƒëi ch∆°i\n",
      "       Ph·∫ßn g√≥c d∆∞·ªõi b√™n tr√°i l√† h√¨nh ·∫£nh tr·∫Øng ƒëen mi√™u t·∫£ m·ªôt gia ƒë√¨nh tan v·ª° v√¨ ng∆∞·ªùi ch·ªìng nghi·ªán ng·∫≠p\n",
      "       Gi·ªØa hai h√¨nh ·∫£nh l√† m·ªôt v·∫øt x√© r√°ch ch√©o (nh∆∞ x√© ƒë√¥i t·ªù gi·∫•y ·∫•y)\n",
      "       High resolution, photorealistic, 8k.\n",
      "\n",
      "‚ö†Ô∏è Failed to parse image data from response: list index out of range\n",
      "Response body: {\"id\":\"eM_5aPfdNdS2vr0PnfTP6QQ\",\"created\":1761202039,\"model\":\"gemini-2.5-flash-image-preview\",\"object\":\"chat.completion\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"content\":\"Tuy nhi√™n, t√¥i kh√¥ng th·ªÉ t·∫°o ra h√¨nh ·∫£nh v·ªõi c√°c k√≠ch th∆∞·ªõc c·ª• th·ªÉ nh∆∞ b·∫°n y√™u c·∫ßu (10*7cm) ho·∫∑c theo ƒë·ªãnh d·∫°ng \\\"ph·∫ßn g√≥c tr√™n b√™n ph·∫£i (ph·∫ßn nh·ªè h∆°n ph·∫ßn g√≥c d∆∞·ªõi b√™n tr√°i)\\\". T√¥i c≈©ng kh√¥ng th·ªÉ tr·ª±c ti·∫øp t·∫°o ra h√¨nh ·∫£nh tr·∫Øng ƒëen.\\n\\nThay v√†o ƒë√≥, t√¥i c√≥ th·ªÉ t·∫°o ra m·ªôt h√¨nh ·∫£nh v·ªõi c√°c y·∫øu t·ªë m√† b·∫°n ƒë√£ m√¥ t·∫£, bao g·ªìm m·ªôt gia ƒë√¨nh h·∫°nh ph√∫c v√† m·ªôt gia ƒë√¨nh tan v·ª°, v·ªõi m·ªôt v·∫øt x√© ch√©o ·ªü gi·ªØa ƒë·ªÉ ph√¢n chia hai c·∫£nh. T√¥i s·∫Ω c·ªë g·∫Øng t·∫°o ra h√¨nh ·∫£nh c√≥ ƒë·ªô ph√¢n gi·∫£i cao v√† ch√¢n th·ª±c nh·∫•t c√≥ th·ªÉ.\\n\\nB·∫°n c√≥ mu·ªën t√¥i th·ª≠ t·∫°o h√¨nh ·∫£nh theo c√°ch ƒë√≥ kh√¥ng?\",\"role\":\"assistant\",\"images\":[],\"thinking_blocks\":[]},\"provider_specific_fields\":{}}],\"usage\":{\"completion_tokens\":149,\"prompt_tokens\":124,\"total_tokens\":273,\"prompt_tokens_details\":{\"text_tokens\":124}},\"vertex_ai_grounding_metadata\":[],\"vertex_ai_url_context_metadata\":[],\"vertex_ai_safety_results\":[],\"vertex_ai_citation_metadata\":[]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ThucChienImageGenerator:\n",
    "   \"\"\"Client sinh h√¨nh ·∫£nh qua gateway AI Th·ª±c Chi·∫øn (chu·∫©n OpenAI / Gemini).\"\"\"\n",
    "\n",
    "\n",
    "   def __init__(self,\n",
    "                base_url: str = \"https://api.thucchien.ai/v1\",\n",
    "                api_key: Optional[str] = None,\n",
    "                debug: bool = False):\n",
    "       self.base_url = base_url.rstrip(\"/\")\n",
    "       self.api_key = api_key or os.getenv(\"LITELLM_API_KEY\", \"\")\n",
    "       self.debug = debug\n",
    "       self.headers = {\n",
    "           \"Content-Type\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "       }\n",
    "\n",
    "\n",
    "   def generate_image(self,\n",
    "                      prompt: str,\n",
    "                      model: str = \"gemini-2.5-flash-image-preview\",\n",
    "                      output_path: str = \"generated_image.png\") -> Optional[str]:\n",
    "       \"\"\"\n",
    "       Sinh ·∫£nh t·ª´ m√¥ t·∫£ vƒÉn b·∫£n (prompt) b·∫±ng model gemini-flash-image-preview.\n",
    "\n",
    "\n",
    "       Args:\n",
    "           prompt: m√¥ t·∫£ h√¨nh ·∫£nh c·∫ßn sinh\n",
    "           model: model d√πng ƒë·ªÉ sinh (vd: gemini-2.5-flash-image-preview)\n",
    "           output_path: n∆°i l∆∞u ·∫£nh k·∫øt qu·∫£\n",
    "       \"\"\"\n",
    "       url = f\"{self.base_url}/chat/completions\"\n",
    "       data = {\n",
    "           \"model\": model,\n",
    "           \"messages\": [\n",
    "               {\"role\": \"user\", \"content\": prompt}\n",
    "           ]\n",
    "       }\n",
    "\n",
    "\n",
    "       print(f\"üé® Generating image using model: {model}\")\n",
    "       print(f\"üñãÔ∏è Prompt: {prompt}\\n\")\n",
    "\n",
    "\n",
    "       try:\n",
    "           response = requests.post(url, headers=self.headers, data=json.dumps(data))\n",
    "           response.raise_for_status()\n",
    "           result = response.json()\n",
    "\n",
    "\n",
    "           if self.debug:\n",
    "               print(\"\\n--- RAW RESPONSE ---\")\n",
    "               print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "               print(\"--------------------\\n\")\n",
    "\n",
    "\n",
    "           # üß© Tr√≠ch xu·∫•t d·ªØ li·ªáu ·∫£nh base64\n",
    "           base64_string = result['choices'][0]['message']['images'][0]['image_url']['url']\n",
    "\n",
    "\n",
    "           # X·ª≠ l√Ω prefix 'data:image/png;base64,' n·∫øu c√≥\n",
    "           if ',' in base64_string:\n",
    "               _, encoded = base64_string.split(',', 1)\n",
    "           else:\n",
    "               encoded = base64_string\n",
    "\n",
    "\n",
    "           image_data = base64.b64decode(encoded)\n",
    "\n",
    "\n",
    "           # L∆∞u ·∫£nh\n",
    "           with open(output_path, 'wb') as f:\n",
    "               f.write(image_data)\n",
    "\n",
    "\n",
    "           print(f\"‚úÖ Image saved successfully: {output_path}\")\n",
    "           return output_path\n",
    "\n",
    "\n",
    "       except requests.exceptions.RequestException as e:\n",
    "           print(f\"‚ùå Request failed: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "       except (KeyError, IndexError) as e:\n",
    "           print(f\"‚ö†Ô∏è Failed to parse image data from response: {e}\")\n",
    "           if 'response' in locals():\n",
    "               print(f\"Response body: {response.text}\")\n",
    "           return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================== MAIN ======================\n",
    "def main():\n",
    "   base_url = os.getenv(\"LITELLM_BASE_URL\", \"https://api.thucchien.ai/v1\")\n",
    "   api_key = os.getenv(\"LITELLM_API_KEY\", \"sk-JJytUYWGmr5BGv9rVurb2Q\")\n",
    "\n",
    "\n",
    "   generator = ThucChienImageGenerator(base_url=base_url, api_key=api_key, debug=False)\n",
    "\n",
    "\n",
    "   prompt = (\n",
    "       \"\"\"H√£y t·∫°o cho t√¥i m·ªôt h√¨nh ·∫£nh k√≠ch th∆∞·ªõc 10*7cm \n",
    "       Ph·∫ßn g√≥c tr√™n b√™n ph·∫£i (ph·∫ßn nh·ªè h∆°n ph·∫ßn g√≥c d∆∞·ªõi b√™n tr√°i) l√† h√¨nh ·∫£nh m·ªôt gia ƒë√¨nh (cha m·∫π, con c√°i) ƒëang n·∫Øm tay nhau vui v·∫ª ƒëi ch∆°i\n",
    "       Ph·∫ßn g√≥c d∆∞·ªõi b√™n tr√°i l√† h√¨nh ·∫£nh tr·∫Øng ƒëen mi√™u t·∫£ m·ªôt gia ƒë√¨nh tan v·ª° v√¨ ng∆∞·ªùi ch·ªìng nghi·ªán ng·∫≠p\n",
    "       Gi·ªØa hai h√¨nh ·∫£nh l√† m·ªôt v·∫øt x√© r√°ch ch√©o (nh∆∞ x√© ƒë√¥i t·ªù gi·∫•y ·∫•y)\n",
    "       High resolution, photorealistic, 8k.\"\"\"\n",
    "   )\n",
    "\n",
    "\n",
    "   generator.generate_image(prompt, output_path=\"futuristic_city.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022f13f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
